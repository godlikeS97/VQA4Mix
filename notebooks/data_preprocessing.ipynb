{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for VQA4Mix\n",
    "\n",
    "This notebook handles data preprocessing tasks for the VQA4Mix project, including:\n",
    "- Loading and examining data from different categories\n",
    "- Standardizing data formats\n",
    "- Cleaning and preprocessing data\n",
    "- Saving processed data for further use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.data_processing.data_loader import load_json_data, load_annotation_data, save_json_data, convert_df_to_json\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths for each category\n",
    "DATA_PATHS = {\n",
    "    'food': '../data/food/food_annotation.json',\n",
    "    'painting': '../data/painting/paintings.json',\n",
    "    'people': '../data/people/people_data.json',\n",
    "    'cat': '../data/cat/upking_data.json'\n",
    "}\n",
    "\n",
    "# Define output paths for processed data\n",
    "OUTPUT_PATHS = {\n",
    "    'food': '../data/food/food_annotation_modified.json',\n",
    "    'painting': '../data/painting/paintings_modified.json',\n",
    "    'people': '../data/people/people_data_modified.json',\n",
    "    'cat': '../data/cat/upking_data_modified.json'\n",
    "}\n",
    "\n",
    "# Define the category to process (set to None to process all categories)\n",
    "CATEGORY = None  # Options: 'food', 'painting', 'people', 'cat', or None for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_category_data(category):\n",
    "    \"\"\"Load data for a specific category.\"\"\"\n",
    "    file_path = DATA_PATHS[category]\n",
    "    print(f\"Loading {category} data from {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Try loading as a DataFrame\n",
    "        df = load_annotation_data(file_path)\n",
    "        print(f\"Loaded {len(df)} records for {category}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {category} data as DataFrame: {e}\")\n",
    "        try:\n",
    "            # Try loading as raw JSON\n",
    "            data = load_json_data(file_path)\n",
    "            if isinstance(data, list):\n",
    "                df = pd.DataFrame(data)\n",
    "                print(f\"Loaded {len(df)} records for {category} from list\")\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"Unexpected data format for {category}\")\n",
    "                return None\n",
    "        except Exception as e2:\n",
    "            print(f\"Error loading {category} data as raw JSON: {e2}\")\n",
    "            return None\n",
    "\n",
    "# Load data for the specified category or all categories\n",
    "category_data = {}\n",
    "if CATEGORY is not None:\n",
    "    category_data[CATEGORY] = load_category_data(CATEGORY)\n",
    "else:\n",
    "    for category in DATA_PATHS.keys():\n",
    "        category_data[category] = load_category_data(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first row of each category's data\n",
    "for category, df in category_data.items():\n",
    "    if df is not None:\n",
    "        print(f\"\\n{category.upper()} DATA STRUCTURE:\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        print(f\"Sample row:\")\n",
    "        display(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data_format(df, category):\n",
    "    \"\"\"Standardize the data format for a category.\"\"\"\n",
    "    print(f\"Standardizing data format for {category}...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_std = df.copy()\n",
    "    \n",
    "    # Ensure 'id' column exists\n",
    "    if 'id' not in df_std.columns:\n",
    "        if 'image_id' in df_std.columns:\n",
    "            df_std['id'] = df_std['image_id']\n",
    "        else:\n",
    "            df_std['id'] = range(len(df_std))\n",
    "    \n",
    "    # Ensure 'file_path' column exists\n",
    "    if 'file_path' not in df_std.columns:\n",
    "        if 'img_url' in df_std.columns:\n",
    "            df_std['file_path'] = df_std['img_url']\n",
    "        elif 'image_path' in df_std.columns:\n",
    "            df_std['file_path'] = df_std['image_path']\n",
    "        else:\n",
    "            # Create a default file path based on category and id\n",
    "            df_std['file_path'] = df_std['id'].apply(lambda x: f\"../data/{category}/{x}.jpg\")\n",
    "    \n",
    "    # Ensure 'captions' column exists\n",
    "    if 'captions' not in df_std.columns:\n",
    "        if 'reference_caption' in df_std.columns:\n",
    "            # Convert single caption to list format\n",
    "            df_std['captions'] = df_std['reference_caption'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "        elif 'caption' in df_std.columns:\n",
    "            df_std['captions'] = df_std['caption'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df_std['captions'] = [[] for _ in range(len(df_std))]\n",
    "    \n",
    "    # Ensure captions are in list format\n",
    "    df_std['captions'] = df_std['captions'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "    \n",
    "    # Select only the standardized columns\n",
    "    std_columns = ['id', 'file_path', 'captions']\n",
    "    additional_columns = [col for col in df_std.columns if col not in std_columns and not col.startswith('_')]\n",
    "    \n",
    "    return df_std[std_columns + additional_columns]\n",
    "\n",
    "# Standardize data format for each category\n",
    "standardized_data = {}\n",
    "for category, df in category_data.items():\n",
    "    if df is not None:\n",
    "        standardized_data[category] = standardize_data_format(df, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_preprocess_data(df, category):\n",
    "    \"\"\"Clean and preprocess data for a category.\"\"\"\n",
    "    print(f\"Cleaning and preprocessing data for {category}...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Clean file paths\n",
    "    def clean_file_path(path):\n",
    "        if not isinstance(path, str):\n",
    "            return path\n",
    "        \n",
    "        # Replace absolute paths with relative paths\n",
    "        if '/shared/data/' in path:\n",
    "            path = path.replace('/shared/data/', '../data/')\n",
    "        \n",
    "        # Ensure the path contains the category name\n",
    "        if f'/{category}/' not in path and not path.startswith(f'../data/{category}/'):\n",
    "            path = f'../data/{category}/{os.path.basename(path)}'\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    df_clean['file_path'] = df_clean['file_path'].apply(clean_file_path)\n",
    "    \n",
    "    # Clean captions\n",
    "    def clean_caption(caption):\n",
    "        if not isinstance(caption, str):\n",
    "            return caption\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        caption = re.sub(r'\\s+', ' ', caption).strip()\n",
    "        \n",
    "        # Ensure proper punctuation\n",
    "        if not caption.endswith(('.', '!', '?')):\n",
    "            caption += '.'\n",
    "        \n",
    "        return caption\n",
    "    \n",
    "    df_clean['captions'] = df_clean['captions'].apply(lambda captions: [clean_caption(c) for c in captions] if isinstance(captions, list) else captions)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_clean = df_clean.drop_duplicates(subset=['id'])\n",
    "    \n",
    "    # Reset index\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean and preprocess data for each category\n",
    "preprocessed_data = {}\n",
    "for category, df in standardized_data.items():\n",
    "    if df is not None:\n",
    "        preprocessed_data[category] = clean_and_preprocess_data(df, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for each category\n",
    "for category, df in preprocessed_data.items():\n",
    "    if df is not None:\n",
    "        output_path = OUTPUT_PATHS[category]\n",
    "        print(f\"Saving processed data for {category} to {output_path}...\")\n",
    "        convert_df_to_json(df, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify processed data for each category\n",
    "for category in preprocessed_data.keys():\n",
    "    output_path = OUTPUT_PATHS[category]\n",
    "    print(f\"\\nVerifying processed data for {category} from {output_path}...\")\n",
    "    \n",
    "    try:\n",
    "        df = load_annotation_data(output_path)\n",
    "        print(f\"Successfully loaded {len(df)} records for {category}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        print(f\"Sample row:\")\n",
    "        display(df.head(1))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading processed data for {category}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has processed data from all categories and standardized their format for use in the unified pipeline. The processed data is now ready for generating multiple-choice questions and model inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
