{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aeb58f",
   "metadata": {},
   "source": [
    "## Load Food Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43dd2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbeee77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Directory: \n",
    "food_images_directory = '/shared/data/food_data/food_images/'\n",
    "food_annotation_file_path = '/shared/data/food_data/food_annotation_modified.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0458394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a646505",
   "metadata": {},
   "source": [
    "## Generate Multiple Choice Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad9b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random choice in [A, B, C, D]\n",
    "import random\n",
    "\n",
    "def generate_random_choice():\n",
    "    return random.choice(['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ac2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multiple_choice_solution'] = df.apply(lambda x: generate_random_choice(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4658c508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0096.jpg</td>\n",
       "      <td>[Many grilled pork ribs are arranged in a curiously shaped wooden cutlery.]</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0091.jpg</td>\n",
       "      <td>[Two grilled brown-red pork ribs on an oval white dinner plate.]</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0093.jpg</td>\n",
       "      <td>[Three pork ribs drizzled with a rich sauce and served on a white round dinner plate.]</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0084.jpg</td>\n",
       "      <td>[Raw, long, fresh pork ribs next to yellow, good potatoes.]</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "1   2  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0096.jpg   \n",
       "2   3  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0091.jpg   \n",
       "3   4  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0093.jpg   \n",
       "4   5  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0084.jpg   \n",
       "\n",
       "                                                                        reference_caption  \\\n",
       "0          [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "1             [Many grilled pork ribs are arranged in a curiously shaped wooden cutlery.]   \n",
       "2                        [Two grilled brown-red pork ribs on an oval white dinner plate.]   \n",
       "3  [Three pork ribs drizzled with a rich sauce and served on a white round dinner plate.]   \n",
       "4                             [Raw, long, fresh pork ribs next to yellow, good potatoes.]   \n",
       "\n",
       "  multiple_choice_solution  \n",
       "0                        A  \n",
       "1                        D  \n",
       "2                        A  \n",
       "3                        A  \n",
       "4                        A  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b5a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca90e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    ")\n",
    "\n",
    "\n",
    "def generate_multiple_choice_question(reference_caption, correct_choice, level='medium'): \n",
    "    # Define the prompt to generate inferior choices\n",
    "    if level == 'easy':\n",
    "        level_message = \"The distractors are obviously incorrect but still loosely related to the context.\"\n",
    "    elif level == 'medium':\n",
    "        level_message = \"The distractors are somewhat related to the context but contain inaccuracies or non-fluent language.\"\n",
    "    elif level == 'hard':\n",
    "        level_message = \"The distractors are closely related to the context but may confuse someone without careful observation.\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the ground truth caption below:\n",
    "    \"{reference_caption}\"\n",
    "    Generate three plausible but incorrect distractors.\n",
    "    \"{level_message}\"\n",
    "    Format the result as a multiple-choice question. \n",
    "    Question title should be \"Which of the following captions best describes the painting?\".\n",
    "    The correct choice should be placed at choice \"{correct_choice}\". \n",
    "    Do not generate special symbols such as '*'.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "\n",
    "    # Extract the generated multiple-choice question\n",
    "    question = response.choices[0].message.content    \n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007608a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hard question \n",
    "df['multiple_choice_question_hard'] = df.apply(lambda x: generate_multiple_choice_question(x['reference_caption'][0], x['multiple_choice_solution'], level='hard'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fce21b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate medium question\n",
    "df['multiple_choice_question_medium'] = df.apply(lambda x: generate_multiple_choice_question(x['reference_caption'][0], x['multiple_choice_solution'], level='medium'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "933d6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate easy question\n",
    "df['multiple_choice_question_easy'] = df.apply(lambda x: generate_multiple_choice_question(x['reference_caption'][0], x['multiple_choice_solution'], level='easy'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ca74bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 multiple_choice_question_easy  \n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f1970b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].multiple_choice_question_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95aed09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e5631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/food_data/food_annotation_with_MCQ_3_difficulies.json\n"
     ]
    }
   ],
   "source": [
    "# Save the annotation with multiple choice question to output file\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/upking/upking_annotation_with_MCQ_3_difficulies.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ef648",
   "metadata": {},
   "source": [
    "## Perform Multiple Choice Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 multiple_choice_question_easy  \n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "#food_images_directory = '/shared/data/food_data/food_images/'\n",
    "food_annotation_file_path = '/shared/data/upking/upking_annotation_with_MCQ.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cbb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f04f522e",
   "metadata": {},
   "source": [
    "### Use llava model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839664b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "import skimage.io as io\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae119ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8f560521c54a32b42258a77e1d8f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model from local directory \n",
    "model_path = '/shared/model/llava-v1.6-mistral-7b-hf'\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(model_path)\n",
    "\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(model_path, torch_dtype=torch.float16, low_cpu_mem_usage=True, load_in_4bit=True) \n",
    "#model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121f75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_multiple_choice_task_llava(img_url, question):\n",
    "    image = io.imread(img_url)\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # mcq_question = output.split('[/INST]')[0].split('[INST] ')[1].strip()\n",
    "    mcq_answer = output.split('[/INST]')[1].strip()\n",
    "    return mcq_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538636dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_easy'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['img_url'], x['multiple_choice_question_easy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305ad284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_medium'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['img_url'], x['multiple_choice_question_medium']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf76239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_hard'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['img_url'], x['multiple_choice_question_hard']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0669fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy</th>\n",
       "      <th>multiple_choice_prediction_medium</th>\n",
       "      <th>multiple_choice_prediction_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 multiple_choice_question_easy  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.   \n",
       "\n",
       "  multiple_choice_prediction_easy multiple_choice_prediction_medium  \\\n",
       "0                               A                                 A   \n",
       "\n",
       "  multiple_choice_prediction_hard  \n",
       "0                               A  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00ef517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/upking/upking_annotation_with_MCQ_result.json\n"
     ]
    }
   ],
   "source": [
    "# Save the MCQ result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/upking/upking_annotation_with_MCQ_result.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f58338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d92dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Easy: 94.00%\n",
      "Prediction Accuracy Medium: 71.00%\n",
      "Prediction Accuracy Hard: 63.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94, 0.71, 0.63)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76059fa",
   "metadata": {},
   "source": [
    "### Use Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2261f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06f919fd9604b8db02c3143700ea21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/shared/model/Phi-3.5-vision-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Note: set _attn_implementation='eager' if you don't have flash_attn installed\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43m_attn_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meager\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m    \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, \n\u001b[1;32m     19\u001b[0m   trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     20\u001b[0m   num_crops\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     21\u001b[0m ) \n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:559\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    558\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4216\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4218\u001b[0m     (\n\u001b[1;32m   4219\u001b[0m         model,\n\u001b[1;32m   4220\u001b[0m         missing_keys,\n\u001b[1;32m   4221\u001b[0m         unexpected_keys,\n\u001b[1;32m   4222\u001b[0m         mismatched_keys,\n\u001b[1;32m   4223\u001b[0m         offload_index,\n\u001b[1;32m   4224\u001b[0m         error_msgs,\n\u001b[0;32m-> 4225\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4237\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4245\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4246\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4728\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4724\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4725\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4726\u001b[0m                 )\n\u001b[1;32m   4727\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4728\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4732\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4734\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4735\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4742\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4744\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4746\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:993\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    990\u001b[0m         param_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 993\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py:329\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    327\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 329\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoProcessor \n",
    "\n",
    "model_id = \"/shared/model/Phi-3.5-vision-instruct\" \n",
    "\n",
    "# Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_id, \n",
    "  device_map=\"cuda\", \n",
    "  trust_remote_code=True, \n",
    "  torch_dtype=\"auto\", \n",
    "  _attn_implementation='eager'    \n",
    ")\n",
    "\n",
    "# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "processor = AutoProcessor.from_pretrained(model_id, \n",
    "  trust_remote_code=True, \n",
    "  num_crops=4\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea59df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_multiple_choice_task_Phi(img_url, question):\n",
    "    image = Image.open(img_url)\n",
    "\n",
    "    images = []\n",
    "    images.append(image)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"<|image_1|>\\n\" + question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "    ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 10, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    generate_ids = model.generate(**inputs, \n",
    "    eos_token_id=processor.tokenizer.eos_token_id, \n",
    "    **generation_args\n",
    "    )\n",
    "\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, \n",
    "    skip_special_tokens=True, \n",
    "    clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628bf7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "WARNING:transformers_modules.Phi-3.5-vision-instruct.modeling_phi3_v:You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_easy_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['img_url'], x['multiple_choice_question_easy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multiple_choice_prediction_medium_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['img_url'], x['multiple_choice_question_medium']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multiple_choice_prediction_hard_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['img_url'], x['multiple_choice_question_hard']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0432e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the prediction results to output file\n",
    "# # Convert DataFrame to a list of dictionaries\n",
    "# list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# # Save the list of dictionaries to a JSON file\n",
    "# output_file = \"llava_prediction_result_food_image.json\"\n",
    "# with open(output_file, \"w\") as file:\n",
    "#     json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "# print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "def calculate_multiple_choice_question_accuracy_Phi(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_Phi\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_Phi\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_Phi\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a472fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 87.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy_Phi(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33e34b",
   "metadata": {},
   "source": [
    "## ~~Perform Image Captioning Task~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fc753d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                   multiple_choice_question  \n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "#food_images_directory = '/shared/data/food_data/food_images/'\n",
    "food_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b51ee0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_image_captioning_task_llava(img_url):\n",
    "    image = Image.open(img_url)\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": \"Generate a caption for this image.\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    caption = output.split('[/INST]')[1].strip()\n",
    "    print(caption)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "510030c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the moment before the feast begins.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the flavors of a succulent barbecue ribs feast.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the smoky, savory flavor of a perfectly grilled rib.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the flavors of a succulent barbecue ribs meal.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of succulent ribs, crispy potatoes, and a refreshing can of soda.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the taste of a succulent BBQ rib, garnished with fresh herbs and a tangy sauce, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the flavors of a succulent barbecue rib.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the moment before the feast begins.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the taste of a delicious, crispy snack.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of succulent meat and creamy beans, served on a rustic wooden table.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful treat, a slice of cake with a dusting of powdered sugar, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful plate of crispy, golden-brown fried dumplings, garnished with a sprinkle of sugar and served with a refreshing slice of orange.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of freshly baked pastries, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful breakfast spread featuring a stack of golden pancakes, a glass of refreshing milk, and a side of fluffy donuts.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of sweet treats, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful trio of golden brown dumplings, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A tantalizing treat, a sugar-coated doughnut, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of powdered sugar-covered pastries, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful treat: powdered sugar-covered pastries on a plate, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of freshly baked pastries, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious seafood stir fry with noodles and a variety of ingredients.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp noodle soup, ready to warm up a chilly day!\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp noodle soup, garnished with a soft-boiled egg and fresh herbs, ready to warm the soul.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of seafood noodle soup, ready to warm the soul.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty seafood dish, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of noodles, seafood, and greens, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious and colorful meal of noodles, seafood, and a side of soup, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp noodle soup, ready to warm the soul on a chilly day.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of noodles, topped with succulent meat and garnished with a sprinkle of sesame seeds.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp and noodle soup, filled with vibrant colors and flavors.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and beans, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and beans, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and beans, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and greens, served in a rustic cast iron skillet.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and beans, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and pasta, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage, potatoes, and a side of fresh vegetables.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Preparing a hearty meal with freshly chopped ginger root and a sharp knife.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and pasta, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and onions, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary experience awaits with these skewered delights, garnished with a touch of elegance.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary scene featuring freshly made dough balls, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A colorful culinary adventure: Five mini pizzas, each with its own unique toppings, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant red dish filled with freshly sliced white radishes, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful stack of crispy, golden-brown pancakes, topped with a dollop of creamy peanut butter, served on a charming blue and white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary experience featuring a trio of golden-brown, crispy tofu squares, garnished with a sprig of fresh green herbs, served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A moment of culinary artistry: freshly grated parmesan cheese being added to a dish.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful snack of apple slices and peanut butter on a bed of crunchy rice cakes.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of sushi with a vibrant green seaweed topping, resting on a textured surface.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of avocado toast topped with a sprinkle of sprouts and a drizzle of creamy sauce, served on a rustic wooden table.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful sushi meal, complete with a refreshing drink and a side of spices.\"\n",
      "\"A delightful culinary experience awaits with these two mouth-watering sushi rolls, each meticulously crafted and ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A colorful and appetizing bento box, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful plate of sushi rolls, garnished with a sprinkle of sesame seeds and a drizzle of soy sauce, ready to be savored.\"\n",
      "\"A delightful bite of sushi rice, topped with a slice of seaweed, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious and healthy meal, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful snack of sushi rice balls, topped with a vibrant orange filling, served on a white plate with a side of soy sauce.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful sushi dish, served on a black plate with a touch of orange, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful plate of sushi rolls, garnished with sesame seeds and green onions, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A culinary delight: Japanese onigiri, meticulously crafted with a sprinkle of spice.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful medley of fresh fruits and a flaky pastry, perfect for a summer afternoon.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: a delicious piece of pie on a gold plate, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A creamy cheesecake with a golden crust, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: a delicious dessert with a hint of citrus.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A stack of golden, flaky waffles topped with a dollop of whipped cream and a slice of lemon, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A perfectly baked pie with a flaky crust, topped with a scoop of vanilla ice cream, all ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dessert scene featuring a slice of lemon meringue pie, a scoop of ice cream, and a sprinkle of powdered sugar, all served on a charming blue plate with a yellow checkered napkin.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A tantalizing dessert with a golden crust and a fluffy meringue topping.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A delicious, creamy slice of lemon meringue pie.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A delicious dessert served on a fine china plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious meal of sliced chicken with a side of flavorful sauce, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of tender, succulent chicken pieces, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful meal of succulent chicken in a vibrant sauce, served on a traditional blue and white plate, accompanied by a refreshing side of soup.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious and hearty meal of chicken and broccoli in a savory sauce, garnished with a sprig of parsley and a purple flower, served on a bamboo placemat.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of crispy, golden-brown fried chicken, served on a pristine white plate, garnished with a sprig of parsley and a vibrant purple flower, ready to be savored.\"\n",
      "\"A tantalizing dish of succulent chicken, garnished with a vibrant red tomato and a sprig of fresh parsley, served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of roasted chicken, garnished with a sprig of parsley and a purple flower, served on a white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A tantalizing dish of succulent pork belly, served with a side of vibrant green onions, all presented on a rustic wooden table.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary experience featuring succulent chicken and fresh herbs, served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful meal of succulent chicken, fresh carrots, and aromatic parsley, all served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and healthy Mediterranean-style salad, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful Mediterranean feast, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and appetizing meal, ready to be savored!\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and healthy salad, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful spread of appetizers, ready to be savored.\"\n",
      "\"A vibrant salad of fresh tomatoes, crisp lettuce, and creamy cheese, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant medley of fresh vegetables and crumbled feta cheese, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and healthy salad, bursting with fresh vegetables and a sprinkle of feta cheese.\"\n",
      "\"A vibrant medley of fresh vegetables and juicy tomatoes, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant salad, bursting with colors and flavors.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dessert moment captured on a floral-patterned plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Homemade pie cooling on the stove, ready to be served.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A cozy meal of comfort food, featuring a hearty casserole and a side of fresh greens.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A tantalizing view of a pecan pie, freshly baked and ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of delicious pie, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of a classic shepherd's pie, topped with a golden crust and served with a side of creamy baked beans.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of pie, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A freshly baked pie, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A golden-brown pie crust, ready for a delicious filling.\"\n",
      "\"A delicious, homemade pizza, freshly baked and ready to be enjoyed.\"\n"
     ]
    }
   ],
   "source": [
    "df['predicted_caption'] = df.apply(lambda x: perform_image_captioning_task_llava(x['img_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc9f48f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>predicted_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>\"Savoring the moment before the feast begins.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Many grilled pork ribs are arranged in a curiously shaped wooden cutlery.]</td>\n",
       "      <td>\"Savoring the flavors of a succulent barbecue ribs feast.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Two grilled brown-red pork ribs on an oval white dinner plate.]</td>\n",
       "      <td>\"Savoring the smoky, savory flavor of a perfectly grilled rib.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Three pork ribs drizzled with a rich sauce and served on a white round dinner plate.]</td>\n",
       "      <td>\"Savoring the flavors of a succulent barbecue ribs meal.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Raw, long, fresh pork ribs next to yellow, good potatoes.]</td>\n",
       "      <td>\"A hearty meal of succulent ribs, crispy potatoes, and a refreshing can of soda.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[A golden bean pie and some pork fried soybeans on a white round plate]</td>\n",
       "      <td>\"A hearty meal of a classic shepherd's pie, topped with a golden crust and served with a side of creamy baked beans.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[A plate of bean pie with a yellow edge and orange skin, and a napkin, a fork, and a knife next to it.]</td>\n",
       "      <td>\"A slice of pie, ready to be savored.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[A dark brown bean pie with a golden edge on a tray placed on a stainless steel net.]</td>\n",
       "      <td>\"A freshly baked pie, ready to be enjoyed.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[a bean pie with scratches on the crispy surface which is caramel color fading from the edge to the center.]</td>\n",
       "      <td>\"A golden-brown pie crust, ready for a delicious filling.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[a baked pie made of beans covered with coriander put on a green plate with a floral border.]</td>\n",
       "      <td>\"A delicious, homemade pizza, freshly baked and ready to be enjoyed.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               reference_caption  \\\n",
       "0                                 [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "1                                    [Many grilled pork ribs are arranged in a curiously shaped wooden cutlery.]   \n",
       "2                                               [Two grilled brown-red pork ribs on an oval white dinner plate.]   \n",
       "3                         [Three pork ribs drizzled with a rich sauce and served on a white round dinner plate.]   \n",
       "4                                                    [Raw, long, fresh pork ribs next to yellow, good potatoes.]   \n",
       "..                                                                                                           ...   \n",
       "95                                       [A golden bean pie and some pork fried soybeans on a white round plate]   \n",
       "96       [A plate of bean pie with a yellow edge and orange skin, and a napkin, a fork, and a knife next to it.]   \n",
       "97                         [A dark brown bean pie with a golden edge on a tray placed on a stainless steel net.]   \n",
       "98  [a bean pie with scratches on the crispy surface which is caramel color fading from the edge to the center.]   \n",
       "99                 [a baked pie made of beans covered with coriander put on a green plate with a floral border.]   \n",
       "\n",
       "                                                                                                        predicted_caption  \n",
       "0                                                                          \"Savoring the moment before the feast begins.\"  \n",
       "1                                                              \"Savoring the flavors of a succulent barbecue ribs feast.\"  \n",
       "2                                                         \"Savoring the smoky, savory flavor of a perfectly grilled rib.\"  \n",
       "3                                                               \"Savoring the flavors of a succulent barbecue ribs meal.\"  \n",
       "4                                       \"A hearty meal of succulent ribs, crispy potatoes, and a refreshing can of soda.\"  \n",
       "..                                                                                                                    ...  \n",
       "95  \"A hearty meal of a classic shepherd's pie, topped with a golden crust and served with a side of creamy baked beans.\"  \n",
       "96                                                                                 \"A slice of pie, ready to be savored.\"  \n",
       "97                                                                            \"A freshly baked pie, ready to be enjoyed.\"  \n",
       "98                                                             \"A golden-brown pie crust, ready for a delicious filling.\"  \n",
       "99                                                  \"A delicious, homemade pizza, freshly baked and ready to be enjoyed.\"  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['reference_caption', 'predicted_caption']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0f3de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/food_data/food_annotation_with_image_captioning_result.json\n"
     ]
    }
   ],
   "source": [
    "# Save the image_captioning result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/food_data/food_annotation_with_image_captioning_result.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e19d3d",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae28d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104932c",
   "metadata": {},
   "source": [
    "### Multiple Choice Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f93141d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question</th>\n",
       "      <th>multiple_choice_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                   multiple_choice_question  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.   \n",
       "\n",
       "  multiple_choice_prediction  \n",
       "0                          A  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "food_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ_result.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32a0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02acaf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Easy: 94.00%\n",
      "Prediction Accuracy Medium: 71.00%\n",
      "Prediction Accuracy Hard: 63.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94, 0.71, 0.63)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff5a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62a7399c",
   "metadata": {},
   "source": [
    "### Caption Quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01e8d555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question</th>\n",
       "      <th>predicted_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.</td>\n",
       "      <td>\"Savoring the moment before the feast begins.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                   multiple_choice_question  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.   \n",
       "\n",
       "                                predicted_caption  \n",
       "0  \"Savoring the moment before the feast begins.\"  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "food_annotation_file_path = '/shared/data/food_data/food_annotation_with_image_captioning_result.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22eb2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "# BLEU Evaluation (Average across multiple references)\n",
    "def evaluate_bleu(df):\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption']  # Predicted caption\n",
    "\n",
    "        # Tokenize the candidate and reference captions\n",
    "        tokenized_references = [ref.strip('\"').split() for ref in references]  # List of tokenized references\n",
    "        tokenized_candidate = candidate.strip('\"').split()  # Tokenized candidate\n",
    "\n",
    "        # Compute BLEU for all references\n",
    "        row_bleu_scores = [\n",
    "            sentence_bleu([ref], tokenized_candidate) for ref in tokenized_references\n",
    "        ]\n",
    "        \n",
    "        # Average across references\n",
    "        bleu_scores.append(sum(row_bleu_scores) / len(row_bleu_scores))\n",
    "    \n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
    "    return bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ecf440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.571883312829026e-232,\n",
       " 8.962731118674859e-232,\n",
       " 9.269981669466712e-232,\n",
       " 5.746727420065187e-232,\n",
       " 0.0,\n",
       " 1.1337861261109773e-231,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6.085166479973199e-232,\n",
       " 1.0662520804273401e-231,\n",
       " 1.268852357850863e-231,\n",
       " 5.035580399326033e-155,\n",
       " 0.0,\n",
       " 2.6616657200018397e-78,\n",
       " 6.695492068419091e-232,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 5.748666558742058e-232,\n",
       " 0.0,\n",
       " 5.294085324363193e-232,\n",
       " 1.0709749285266912e-231,\n",
       " 4.491405484477833e-232,\n",
       " 1.0244914152188952e-231,\n",
       " 9.065607048138757e-232,\n",
       " 2.738929881729733e-232,\n",
       " 6.085166479973199e-232,\n",
       " 1.8423401430089077e-155,\n",
       " 4.685504009359912e-155,\n",
       " 1.3416480207402436e-231,\n",
       " 8.672642734733089e-232,\n",
       " 9.134374972545899e-232,\n",
       " 1.1896457329133973e-231,\n",
       " 1.0003688322288243e-231,\n",
       " 5.347469696085671e-155,\n",
       " 1.1896457329133973e-231,\n",
       " 0.0,\n",
       " 1.0709749285266912e-231,\n",
       " 5.554837769749797e-155,\n",
       " 0.0,\n",
       " 1.0003688322288243e-231,\n",
       " 2.5573972968570177e-155,\n",
       " 4.801280454758726e-232,\n",
       " 5.586496301804011e-232,\n",
       " 1.154647032204335e-231,\n",
       " 4.447844384793538e-155,\n",
       " 9.594503055152632e-232,\n",
       " 1.1200407237786664e-231,\n",
       " 4.930629612556808e-155,\n",
       " 1.1008876702055895e-231,\n",
       " 1.1640469867513693e-231,\n",
       " 1.1200407237786664e-231,\n",
       " 8.726094729337945e-232,\n",
       " 7.58961907326157e-232,\n",
       " 3.952279160832715e-155,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.101024727239516e-155,\n",
       " 6.113456099502214e-155,\n",
       " 4.368048869756373e-155,\n",
       " 4.654437852936961e-232,\n",
       " 2.0140843428031594e-78,\n",
       " 1.268852357850863e-231,\n",
       " 4.3593518747857304e-155,\n",
       " 9.918892480173173e-232,\n",
       " 4.811208997101563e-155,\n",
       " 4.717068855239749e-155,\n",
       " 5.308748212294969e-155,\n",
       " 1.12925133750994e-231,\n",
       " 1.4809931627947726e-78,\n",
       " 2.77975147435408e-155,\n",
       " 2.514766346395224e-155,\n",
       " 4.3382562373312645e-155,\n",
       " 1.0356031510602797e-231,\n",
       " 0.10248656832135973,\n",
       " 2.5241848589197885e-78,\n",
       " 4.431329581760117e-155,\n",
       " 2.166832421212117e-78,\n",
       " 4.15475484660171e-155,\n",
       " 3.0333872372477996e-155,\n",
       " 8.47838036897581e-232,\n",
       " 3.0857088441767165e-232,\n",
       " 0.0,\n",
       " 2.833381309242575e-233,\n",
       " 1.692841243110689e-232,\n",
       " 8.691336740174417e-233,\n",
       " 1.355408971519012e-231,\n",
       " 3.429482526394057e-155,\n",
       " 1.1008876702055895e-231,\n",
       " 7.332960415391412e-232,\n",
       " 1.929421779987532e-232,\n",
       " 3.4625676872110776e-232,\n",
       " 4.481994719908145e-232,\n",
       " 9.424890216415306e-232,\n",
       " 1.0428282296630707e-231,\n",
       " 6.744160953836975e-232,\n",
       " 1.1896457329133973e-231,\n",
       " 2.1863213053063146e-232,\n",
       " 3.103614158540553e-232,\n",
       " 3.6846889193984664e-232,\n",
       " 5.294085324363193e-232]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bleu(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1191486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/过隙de白驹/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# METEOR Evaluation (Average across multiple references)\n",
    "def evaluate_meteor(df):\n",
    "    meteor_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption'].strip('\"')  # Predicted caption (raw string)\n",
    "\n",
    "        # Compute METEOR for all references\n",
    "        row_meteor_scores = [\n",
    "            meteor_score([[ref]], [candidate]) for ref in references\n",
    "        ]\n",
    "        \n",
    "        # Average across references\n",
    "        meteor_scores.append(sum(row_meteor_scores) / len(row_meteor_scores))\n",
    "    \n",
    "    avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "    print(f\"Average METEOR: {avg_meteor:.4f}\")\n",
    "    return meteor_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef6f6412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average METEOR: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_meteor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9438e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9946f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE Evaluation (Average across multiple references)\n",
    "def evaluate_rouge(df):\n",
    "    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption']  # Predicted caption\n",
    "        \n",
    "        # Compute ROUGE scores for all references\n",
    "        row_rouge1_scores, row_rouge2_scores, row_rougeL_scores = [], [], []\n",
    "        for ref in references:\n",
    "            scores = scorer.score(ref, candidate.strip('\"'))\n",
    "            row_rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            row_rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            row_rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        \n",
    "        # Average across references\n",
    "        rouge1_scores.append(sum(row_rouge1_scores) / len(row_rouge1_scores))\n",
    "        rouge2_scores.append(sum(row_rouge2_scores) / len(row_rouge2_scores))\n",
    "        rougeL_scores.append(sum(row_rougeL_scores) / len(row_rougeL_scores))\n",
    "    \n",
    "    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
    "    avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
    "    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
    "    \n",
    "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "    print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")\n",
    "    return rouge1_scores, rouge2_scores, rougeL_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e707a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: 0.4267\n",
      "Average ROUGE-2: 0.1000\n",
      "Average ROUGE-L: 0.3457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.3157894736842105, 0.5714285714285714, 0.3928571428571428],\n",
       " [0.0, 0.3, 0.0],\n",
       " [0.2631578947368421, 0.5238095238095238, 0.25])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rouge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIDEr and SPICE (unchanged, since they handle multiple references internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9a9ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cider(df):\n",
    "    ref_dict = {str(idx): row['reference_caption'] for idx, row in df.iterrows()}\n",
    "    cand_dict = {str(idx): [row['predicted_caption']] for idx, row in df.iterrows()}\n",
    "    \n",
    "    cider_scorer = Cider()\n",
    "    score, _ = cider_scorer.compute_score(ref_dict, cand_dict)\n",
    "    print(f\"Average CIDEr: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab777ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CIDEr: 0.7787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7786648935891062"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_cider(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618198b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3466d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_spice(df):\n",
    "    ref_dict = {str(idx): row['reference_caption'] for idx, row in df.iterrows()}\n",
    "    cand_dict = {str(idx): [row['predicted_caption']] for idx, row in df.iterrows()}\n",
    "    \n",
    "    spice_scorer = Spice()\n",
    "    score, _ = spice_scorer.compute_score(ref_dict, cand_dict)\n",
    "    print(f\"Average SPICE: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db09381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/opt/conda/lib/python3.10/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.890 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.995 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.85 s\n",
      "Average SPICE: 0.2341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23411371237458198"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_spice(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1614075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
