{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aeb58f",
   "metadata": {},
   "source": [
    "## Load Food Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43dd2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cbeee77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>url</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512533</td>\n",
       "      <td>COCO_train2014_000000512533.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg</td>\n",
       "      <td>[A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        file_name  \\\n",
       "0  512533  COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                       url  \\\n",
       "0  http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       captions  \n",
       "0  [A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Directory: \n",
    "# food_images_directory = '/shared/data/food_data/food_images/'\n",
    "food_annotation_file_path = '/shared/data/stephen/car_data.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0458394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a646505",
   "metadata": {},
   "source": [
    "## Generate Multiple Choice Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ad9b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random choice in [A, B, C, D]\n",
    "import random\n",
    "\n",
    "def generate_random_choice():\n",
    "    return random.choice(['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1ac2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multiple_choice_solution'] = df.apply(lambda x: generate_random_choice(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4658c508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>url</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512533</td>\n",
       "      <td>COCO_train2014_000000512533.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg</td>\n",
       "      <td>[A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315713</td>\n",
       "      <td>COCO_train2014_000000315713.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000315713.jpg</td>\n",
       "      <td>[A young girl about to bite into a hotdog dotted with mustard and ketchup, A girl makes a face as she eats a hot dog., A little girl is attempting to eat a hot dog., THERE IS A GIRL THAT IS EATING A HOT DOG , A girl getting ready to bite into a hotdog ]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309791</td>\n",
       "      <td>COCO_train2014_000000309791.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000309791.jpg</td>\n",
       "      <td>[A street on the side of which shops are  decorated and flowering potted plants are kept., An outdoor city market selling trees, shrubs, and flowers., People at an outdoor market under a canopy., a market area with plants and people standing by, Market stands in city center with Christmas decorations.]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496434</td>\n",
       "      <td>COCO_train2014_000000496434.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000496434.jpg</td>\n",
       "      <td>[A woman standing a tennis court holding a tennis racquet., A tennis player playing tennis in a tennis court., A woman on a tennis court serving the ball., a woman looking up at a tennis ball, A woman reaches up  toward a tennis ball]</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>567630</td>\n",
       "      <td>COCO_train2014_000000567630.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000567630.jpg</td>\n",
       "      <td>[A couple of girls with tennis rackets in a room., A couple of girls holding tennis racquets and a ball., Two young girls standing next to each other with racquets., The two girls are getting ready to play tennis., Two girlw holding tennis rackets in a room]</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        file_name  \\\n",
       "0  512533  COCO_train2014_000000512533.jpg   \n",
       "1  315713  COCO_train2014_000000315713.jpg   \n",
       "2  309791  COCO_train2014_000000309791.jpg   \n",
       "3  496434  COCO_train2014_000000496434.jpg   \n",
       "4  567630  COCO_train2014_000000567630.jpg   \n",
       "\n",
       "                                                                       url  \\\n",
       "0  http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg   \n",
       "1  http://images.cocodataset.org/train2014/COCO_train2014_000000315713.jpg   \n",
       "2  http://images.cocodataset.org/train2014/COCO_train2014_000000309791.jpg   \n",
       "3  http://images.cocodataset.org/train2014/COCO_train2014_000000496434.jpg   \n",
       "4  http://images.cocodataset.org/train2014/COCO_train2014_000000567630.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          captions  \\\n",
       "0                                     [A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]   \n",
       "1                                                    [A young girl about to bite into a hotdog dotted with mustard and ketchup, A girl makes a face as she eats a hot dog., A little girl is attempting to eat a hot dog., THERE IS A GIRL THAT IS EATING A HOT DOG , A girl getting ready to bite into a hotdog ]   \n",
       "2  [A street on the side of which shops are  decorated and flowering potted plants are kept., An outdoor city market selling trees, shrubs, and flowers., People at an outdoor market under a canopy., a market area with plants and people standing by, Market stands in city center with Christmas decorations.]   \n",
       "3                                                                       [A woman standing a tennis court holding a tennis racquet., A tennis player playing tennis in a tennis court., A woman on a tennis court serving the ball., a woman looking up at a tennis ball, A woman reaches up  toward a tennis ball]   \n",
       "4                                               [A couple of girls with tennis rackets in a room., A couple of girls holding tennis racquets and a ball., Two young girls standing next to each other with racquets., The two girls are getting ready to play tennis., Two girlw holding tennis rackets in a room]   \n",
       "\n",
       "  multiple_choice_solution  \n",
       "0                        C  \n",
       "1                        C  \n",
       "2                        C  \n",
       "3                        B  \n",
       "4                        B  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b5a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca90e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    ")\n",
    "\n",
    "\n",
    "def generate_multiple_choice_question(reference_caption, correct_choice, level='medium'): \n",
    "    # Define the prompt to generate inferior choices\n",
    "    if level == 'easy':\n",
    "        level_message = \"The distractors are obviously incorrect but still loosely related to the context.\"\n",
    "    elif level == 'medium':\n",
    "        level_message = \"The distractors are somewhat related to the context but contain inaccuracies or non-fluent language.\"\n",
    "    elif level == 'hard':\n",
    "        level_message = \"The distractors are closely related to the context but may confuse someone without careful observation.\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the ground truth caption below:\n",
    "    \"{reference_caption}\"\n",
    "    Generate three plausible but incorrect distractors.\n",
    "    \"{level_message}\"\n",
    "    Format the result as a multiple-choice question. \n",
    "    Question title should be \"Which of the following captions best describes the painting?\".\n",
    "    The correct choice should be placed at choice \"{correct_choice}\". \n",
    "    Do not generate special symbols such as '*'.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "\n",
    "    # Extract the generated multiple-choice question\n",
    "    question = response.choices[0].message.content    \n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007608a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hard question \n",
    "df['multiple_choice_question_hard'] = df.apply(lambda x: generate_multiple_choice_question(x['captions'][0], x['multiple_choice_solution'], level='hard'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce21b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate medium question\n",
    "df['multiple_choice_question_medium'] = df.apply(lambda x: generate_multiple_choice_question(x['captions'][0], x['multiple_choice_solution'], level='medium'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate easy question\n",
    "df['multiple_choice_question_easy'] = df.apply(lambda x: generate_multiple_choice_question(x['captions'][0], x['multiple_choice_solution'], level='easy'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca74bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1970b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].multiple_choice_question_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95aed09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the annotation with multiple choice question to output file\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/stephen/people_annotation_with_MCQ_3_difficulies.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ef648",
   "metadata": {},
   "source": [
    "## Perform Multiple Choice Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "002b381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>url</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512533</td>\n",
       "      <td>COCO_train2014_000000512533.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg</td>\n",
       "      <td>[A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]</td>\n",
       "      <td>D</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        file_name  \\\n",
       "0  512533  COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                       url  \\\n",
       "0  http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       captions  \\\n",
       "0  [A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        D   \n",
       "\n",
       "                                                                                                                                                                                                                                                         multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                            multiple_choice_question_easy  \n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "#food_images_directory = '/shared/data/food_data/food_images/'\n",
    "food_annotation_file_path = \"/shared/data/stephen/people_annotation_with_MCQ_3_difficulies.json\"\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cbb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f04f522e",
   "metadata": {},
   "source": [
    "### Use llava model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "839664b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ae119ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2d20b1406946a6b147d66fe5c2b399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model from local directory \n",
    "model_path = '/shared/model/llava-v1.6-mistral-7b-hf'\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(model_path)\n",
    "\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(model_path, torch_dtype=torch.float16, low_cpu_mem_usage=True, load_in_4bit=True) \n",
    "#model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a6480",
   "metadata": {},
   "source": [
    "#### Without image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "121f75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def perform_multiple_choice_task_llava(img_url, question):\n",
    "    # 下载图片\n",
    "    response = requests.get(img_url)\n",
    "    response.raise_for_status()  # 检查下载是否成功\n",
    "    image = Image.open(BytesIO(response.content))  # 将图片加载到内存中\n",
    "\n",
    "    # 构建对话\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "                {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # 自动回归生成结果\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # 提取答案\n",
    "    mcq_answer = output.split('[/INST]')[1].strip()\n",
    "    return mcq_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "538636dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_easy'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['url'], x['multiple_choice_question_easy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "305ad284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_medium'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['url'], x['multiple_choice_question_medium']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cf76239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_hard'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['url'], x['multiple_choice_question_hard']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc0669fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>url</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy</th>\n",
       "      <th>multiple_choice_prediction_medium</th>\n",
       "      <th>multiple_choice_prediction_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512533</td>\n",
       "      <td>COCO_train2014_000000512533.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg</td>\n",
       "      <td>[A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]</td>\n",
       "      <td>D</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        file_name  \\\n",
       "0  512533  COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                       url  \\\n",
       "0  http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       captions  \\\n",
       "0  [A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        D   \n",
       "\n",
       "                                                                                                                                                                                                                                                         multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                            multiple_choice_question_easy  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "  multiple_choice_prediction_easy multiple_choice_prediction_medium  \\\n",
       "0                               D                                 D   \n",
       "\n",
       "  multiple_choice_prediction_hard  \n",
       "0                               D  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c00ef517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties.json\n"
     ]
    }
   ],
   "source": [
    "# Save the MCQ result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36f58338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62d92dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Easy: 100.00%\n",
      "Prediction Accuracy Medium: 89.00%\n",
      "Prediction Accuracy Hard: 81.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.89, 0.81)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74d8cb",
   "metadata": {},
   "source": [
    "#### With Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ea73f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will apply the augmentation to the image\n",
    "# sin_aug: single augmentation, includes flip, rotate, crop, saturation, artStyle, noise, blur\n",
    "# mul_aug: multiple augmentations in a list\n",
    "# Return a dictionary. Key: augmentation name; Value: augmented image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "\n",
    "def image_augumentation(ori_img, sin_aug = None, mul_aug = None):\n",
    "    img = ori_img.copy()\n",
    "    aug_img = {}\n",
    "    if sin_aug:\n",
    "        if sin_aug == 'flip':\n",
    "            aug_img['flip'] = flip_image(img)\n",
    "        elif sin_aug == 'rotate':\n",
    "            aug_img['rotate'] = rotate_image(img)\n",
    "        elif sin_aug == 'crop':\n",
    "            aug_img['crop'] = random_crop(img)\n",
    "        elif sin_aug == 'saturation':\n",
    "            aug_img['saturation'] = adjust_saturation(img)\n",
    "        elif sin_aug == 'artStyle':\n",
    "            aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "        elif sin_aug == 'noise':\n",
    "            aug_img['noise'] = add_noise(img)\n",
    "        elif sin_aug == 'blur':\n",
    "            aug_img['blur'] = blur_image(img)\n",
    "        else:\n",
    "            aug_img['original'] = img\n",
    "\n",
    "    elif mul_aug:\n",
    "        for aug in mul_aug:\n",
    "            if aug == 'flip':\n",
    "                aug_img['flip'] = flip_image(img)\n",
    "            elif aug == 'rotate':\n",
    "                aug_img['rotate'] = rotate_image(img)\n",
    "            elif aug == 'crop':\n",
    "                aug_img['crop'] = random_crop(img)\n",
    "            elif aug == 'saturation':\n",
    "                aug_img['saturation'] = adjust_saturation(img)\n",
    "            elif aug == 'artStyle':\n",
    "                aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "            elif aug == 'noise':\n",
    "                aug_img['noise'] = add_noise(img)\n",
    "            elif aug == 'blur':\n",
    "                aug_img['blur'] = blur_image(img)\n",
    "            else:\n",
    "                aug_img['original'] = img\n",
    "    else:\n",
    "        aug_img['original'] = img\n",
    "    return aug_img\n",
    "\n",
    "def flip_image(image):\n",
    "    img = np.flip(image, axis=1)\n",
    "    return img\n",
    "\n",
    "def rotate_image(image, angle_range=(-30, 30)):\n",
    "    angle = random.uniform(*angle_range)\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "    return rotated_image\n",
    "\n",
    "def random_crop(image, percent=0.7):\n",
    "    h, w = image.shape[:2]\n",
    "    # crop_h, crop_w = crop_size\n",
    "    crop_h = round(percent * h)\n",
    "    crop_w = round(percent * w)\n",
    "\n",
    "    top = random.randint(0, h - crop_h)\n",
    "    left = random.randint(0, w - crop_w)\n",
    "    cropped_image = image[top:top + crop_h, left:left + crop_w]\n",
    "    return cropped_image\n",
    "\n",
    "def adjust_saturation(image, factor=5):\n",
    "\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    enhancer = ImageEnhance.Color(image_pil)\n",
    "    saturated_image = enhancer.enhance(factor)\n",
    "    return cv2.cvtColor(np.array(saturated_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def convert_to_artStyle(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a binary threshold\n",
    "    art_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 11, 2)\n",
    "    return art_image\n",
    "\n",
    "def add_noise(image, mean=0, stddev=25):\n",
    "    noise = np.random.normal(mean, stddev, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "def blur_image(image, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b70ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_multiple_choice_task_with_image_augmentation_llava(img_url, question, aug_type=None):\n",
    "    response = requests.get(img_url)\n",
    "    response.raise_for_status()  # 检查下载是否成功\n",
    "    image = Image.open(BytesIO(response.content))  # 将图片加载到内存中\n",
    "\n",
    "    # Convert the PIL Image to a NumPy array\n",
    "    image = np.array(image)\n",
    "\n",
    "    # Apply image augmentation\n",
    "    if (aug_type is not None):\n",
    "        image = image_augumentation(image, sin_aug = aug_type)[aug_type]  \n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # mcq_question = output.split('[/INST]')[0].split('[INST] ')[1].strip()\n",
    "    mcq_answer = output.split('[/INST]')[1].strip()\n",
    "    return mcq_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf05b7a",
   "metadata": {},
   "source": [
    "##### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94e02345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Cropping - easy\n",
    "df['multiple_choice_prediction_easy_crop'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_easy'], 'crop'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0866b6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Cropping - medium\n",
    "df['multiple_choice_prediction_medium_crop'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_medium'], 'crop'), axis=1)\n",
    "# Cropping - hard\n",
    "df['multiple_choice_prediction_hard_crop'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_hard'], 'crop'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e586c",
   "metadata": {},
   "source": [
    "##### saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80044e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Saturation - easy\n",
    "df['multiple_choice_prediction_easy_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_easy'], 'saturation'), axis=1)\n",
    "# Saturation - medium\n",
    "df['multiple_choice_prediction_medium_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_medium'], 'saturation'), axis=1)\n",
    "# Saturation - hard\n",
    "df['multiple_choice_prediction_hard_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_hard'], 'saturation'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bcc7a",
   "metadata": {},
   "source": [
    "##### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f885e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Noise - easy\n",
    "df['multiple_choice_prediction_easy_noise'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_easy'], 'noise'), axis=1)\n",
    "# Noise - medium\n",
    "df['multiple_choice_prediction_medium_noise'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_medium'], 'noise'), axis=1)\n",
    "# Noise - hard\n",
    "df['multiple_choice_prediction_hard_noise'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['url'], x['multiple_choice_question_hard'], 'noise'), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c9f5d",
   "metadata": {},
   "source": [
    "##### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30e4a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties_with_image_augmentation.json\n"
     ]
    }
   ],
   "source": [
    "# Save the MCQ result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties_with_image_augmentation.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36641ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8394b836",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9dccfbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>url</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy</th>\n",
       "      <th>multiple_choice_prediction_medium</th>\n",
       "      <th>multiple_choice_prediction_hard</th>\n",
       "      <th>multiple_choice_prediction_easy_crop</th>\n",
       "      <th>multiple_choice_prediction_medium_crop</th>\n",
       "      <th>multiple_choice_prediction_hard_crop</th>\n",
       "      <th>multiple_choice_prediction_easy_saturation</th>\n",
       "      <th>multiple_choice_prediction_medium_saturation</th>\n",
       "      <th>multiple_choice_prediction_hard_saturation</th>\n",
       "      <th>multiple_choice_prediction_easy_noise</th>\n",
       "      <th>multiple_choice_prediction_medium_noise</th>\n",
       "      <th>multiple_choice_prediction_hard_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512533</td>\n",
       "      <td>COCO_train2014_000000512533.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg</td>\n",
       "      <td>[A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]</td>\n",
       "      <td>D</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        file_name  \\\n",
       "0  512533  COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                       url  \\\n",
       "0  http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       captions  \\\n",
       "0  [A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        D   \n",
       "\n",
       "                                                                                                                                                                                                                                                         multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                            multiple_choice_question_easy  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "  multiple_choice_prediction_easy multiple_choice_prediction_medium  \\\n",
       "0                               D                                 D   \n",
       "\n",
       "  multiple_choice_prediction_hard multiple_choice_prediction_easy_crop  \\\n",
       "0                               D                                    D   \n",
       "\n",
       "  multiple_choice_prediction_medium_crop multiple_choice_prediction_hard_crop  \\\n",
       "0                                      D                                    D   \n",
       "\n",
       "  multiple_choice_prediction_easy_saturation  \\\n",
       "0                                          D   \n",
       "\n",
       "  multiple_choice_prediction_medium_saturation  \\\n",
       "0                                            D   \n",
       "\n",
       "  multiple_choice_prediction_hard_saturation  \\\n",
       "0                                          D   \n",
       "\n",
       "  multiple_choice_prediction_easy_noise  \\\n",
       "0                                     D   \n",
       "\n",
       "  multiple_choice_prediction_medium_noise  \\\n",
       "0                                       D   \n",
       "\n",
       "  multiple_choice_prediction_hard_noise  \n",
       "0                                     D  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "food_annotation_file_path = '/shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties_with_image_augmentation.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e422b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy_with_augmentation(df):\n",
    "    # Calculate accuracy\n",
    "\n",
    "    # crop augmentation\n",
    "    accuracy_easy_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_crop\"]).mean()\n",
    "    accuracy_medium_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_crop\"]).mean()\n",
    "    accuracy_hard_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_crop\"]).mean()\n",
    "\n",
    "    # saturation augmentation\n",
    "    accuracy_easy_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_saturation\"]).mean()\n",
    "    accuracy_medium_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_saturation\"]).mean()\n",
    "    accuracy_hard_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_saturation\"]).mean()\n",
    "\n",
    "    # noise augmentation\n",
    "    accuracy_easy_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_noise\"]).mean()\n",
    "    accuracy_medium_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_noise\"]).mean()\n",
    "    accuracy_hard_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_noise\"]).mean()\n",
    "\n",
    "\n",
    "    print('***** Prediction Accuracy with Crop Augmentation *****')\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy_crop * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium_crop * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_crop * 100:.2f}%\")\n",
    "\n",
    "    print('***** Prediction Accuracy with Saturation Augmentation *****')\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy_saturation * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium_saturation * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_saturation * 100:.2f}%\")\n",
    "\n",
    "    print('***** Prediction Accuracy with Noise Augmentation *****')\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy_noise * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium_noise * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_noise * 100:.2f}%\")\n",
    "\n",
    "\n",
    "    return accuracy_easy_crop, accuracy_medium_crop, accuracy_hard_crop, accuracy_easy_saturation, accuracy_medium_saturation, accuracy_hard_saturation, accuracy_easy_noise, accuracy_medium_noise, accuracy_hard_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "351e53c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Prediction Accuracy with Crop Augmentation *****\n",
      "Prediction Accuracy Easy: 97.00%\n",
      "Prediction Accuracy Medium: 86.00%\n",
      "Prediction Accuracy Hard: 83.00%\n",
      "***** Prediction Accuracy with Saturation Augmentation *****\n",
      "Prediction Accuracy Easy: 100.00%\n",
      "Prediction Accuracy Medium: 88.00%\n",
      "Prediction Accuracy Hard: 83.00%\n",
      "***** Prediction Accuracy with Noise Augmentation *****\n",
      "Prediction Accuracy Easy: 89.00%\n",
      "Prediction Accuracy Medium: 78.00%\n",
      "Prediction Accuracy Hard: 72.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.97, 0.86, 0.83, 1.0, 0.88, 0.83, 0.89, 0.78, 0.72)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy_with_augmentation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268f406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c76059fa",
   "metadata": {},
   "source": [
    "### Use Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca27531e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>url</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512533</td>\n",
       "      <td>COCO_train2014_000000512533.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg</td>\n",
       "      <td>[A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]</td>\n",
       "      <td>D</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        file_name  \\\n",
       "0  512533  COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                       url  \\\n",
       "0  http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       captions  \\\n",
       "0  [A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        D   \n",
       "\n",
       "                                                                                                                                                                                                                                                         multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                            multiple_choice_question_easy  \n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load question dataframe\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "# Data Directory: \n",
    "food_annotation_file_path = '/shared/data/stephen/people_annotation_with_MCQ_3_difficulies.json'\n",
    "\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2261f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ddcf85c580472e9ebebfc0fa6821e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:520: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoProcessor \n",
    "\n",
    "model_id = \"/shared/model/Phi-3.5-vision-instruct\" \n",
    "\n",
    "# Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_id, \n",
    "  device_map=\"cuda\", \n",
    "  trust_remote_code=True, \n",
    "  torch_dtype=\"auto\", \n",
    "  _attn_implementation='eager'    \n",
    ")\n",
    "\n",
    "# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "processor = AutoProcessor.from_pretrained(model_id, \n",
    "  trust_remote_code=True, \n",
    "  num_crops=4\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8ed8b",
   "metadata": {},
   "source": [
    "#### Without image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea59df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def perform_multiple_choice_task_Phi(img_url, question):\n",
    "     # 下载图片\n",
    "    response = requests.get(img_url)\n",
    "    response.raise_for_status()  # 检查下载是否成功\n",
    "    image = Image.open(BytesIO(response.content))  # 将图片加载到内存中\n",
    "\n",
    "    images = []\n",
    "    images.append(image)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"<|image_1|>\\n\" + question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "    ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 10, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    generate_ids = model.generate(**inputs, \n",
    "    eos_token_id=processor.tokenizer.eos_token_id, \n",
    "    **generation_args\n",
    "    )\n",
    "\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, \n",
    "    skip_special_tokens=True, \n",
    "    clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# def perform_multiple_choice_task_llava(img_url, question):\n",
    "#     # 下载图片\n",
    "#     response = requests.get(img_url)\n",
    "#     response.raise_for_status()  # 检查下载是否成功\n",
    "#     image = Image.open(BytesIO(response.content))  # 将图片加载到内存中\n",
    "\n",
    "#     # 构建对话\n",
    "#     conversation = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\"type\": \"text\", \"text\": question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "#                 {\"type\": \"image\"},\n",
    "#             ],\n",
    "#         },\n",
    "#     ]\n",
    "#     prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "#     inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "#     # 自动回归生成结果\n",
    "#     output = model.generate(**inputs, max_new_tokens=150)\n",
    "#     output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "#     # 提取答案\n",
    "#     mcq_answer = output.split('[/INST]')[1].strip()\n",
    "#     return mcq_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "628bf7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "WARNING:transformers_modules.Phi-3.5-vision-instruct.modeling_phi3_v:You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_easy_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['url'], x['multiple_choice_question_easy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bb2ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_medium_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['url'], x['multiple_choice_question_medium']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1926fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_hard_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['url'], x['multiple_choice_question_hard']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0432e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the prediction results to output file\n",
    "# # Convert DataFrame to a list of dictionaries\n",
    "# list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# # Save the list of dictionaries to a JSON file\n",
    "# output_file = \"llava_prediction_result_food_image.json\"\n",
    "# with open(output_file, \"w\") as file:\n",
    "#     json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "# print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75a388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "def calculate_multiple_choice_question_accuracy_Phi(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_Phi\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_Phi\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_Phi\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a472fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Easy: 98.00%\n",
      "Prediction Accuracy Medium: 93.00%\n",
      "Prediction Accuracy Hard: 90.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.98, 0.93, 0.9)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy_Phi(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3acb58",
   "metadata": {},
   "source": [
    "#### With Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccad6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will apply the augmentation to the image\n",
    "# sin_aug: single augmentation, includes flip, rotate, crop, saturation, artStyle, noise, blur\n",
    "# mul_aug: multiple augmentations in a list\n",
    "# Return a dictionary. Key: augmentation name; Value: augmented image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "\n",
    "def image_augumentation(ori_img, sin_aug = None, mul_aug = None):\n",
    "    img = ori_img.copy()\n",
    "    aug_img = {}\n",
    "    if sin_aug:\n",
    "        if sin_aug == 'flip':\n",
    "            aug_img['flip'] = flip_image(img)\n",
    "        elif sin_aug == 'rotate':\n",
    "            aug_img['rotate'] = rotate_image(img)\n",
    "        elif sin_aug == 'crop':\n",
    "            aug_img['crop'] = random_crop(img)\n",
    "        elif sin_aug == 'saturation':\n",
    "            aug_img['saturation'] = adjust_saturation(img)\n",
    "        elif sin_aug == 'artStyle':\n",
    "            aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "        elif sin_aug == 'noise':\n",
    "            aug_img['noise'] = add_noise(img)\n",
    "        elif sin_aug == 'blur':\n",
    "            aug_img['blur'] = blur_image(img)\n",
    "        else:\n",
    "            aug_img['original'] = img\n",
    "\n",
    "    elif mul_aug:\n",
    "        for aug in mul_aug:\n",
    "            if aug == 'flip':\n",
    "                aug_img['flip'] = flip_image(img)\n",
    "            elif aug == 'rotate':\n",
    "                aug_img['rotate'] = rotate_image(img)\n",
    "            elif aug == 'crop':\n",
    "                aug_img['crop'] = random_crop(img)\n",
    "            elif aug == 'saturation':\n",
    "                aug_img['saturation'] = adjust_saturation(img)\n",
    "            elif aug == 'artStyle':\n",
    "                aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "            elif aug == 'noise':\n",
    "                aug_img['noise'] = add_noise(img)\n",
    "            elif aug == 'blur':\n",
    "                aug_img['blur'] = blur_image(img)\n",
    "            else:\n",
    "                aug_img['original'] = img\n",
    "    else:\n",
    "        aug_img['original'] = img\n",
    "    return aug_img\n",
    "\n",
    "def flip_image(image):\n",
    "    img = np.flip(image, axis=1)\n",
    "    return img\n",
    "\n",
    "def rotate_image(image, angle_range=(-30, 30)):\n",
    "    angle = random.uniform(*angle_range)\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "    return rotated_image\n",
    "\n",
    "def random_crop(image, percent=0.7):\n",
    "    h, w = image.shape[:2]\n",
    "    # crop_h, crop_w = crop_size\n",
    "    crop_h = round(percent * h)\n",
    "    crop_w = round(percent * w)\n",
    "\n",
    "    top = random.randint(0, h - crop_h)\n",
    "    left = random.randint(0, w - crop_w)\n",
    "    cropped_image = image[top:top + crop_h, left:left + crop_w]\n",
    "    return cropped_image\n",
    "\n",
    "def adjust_saturation(image, factor=5):\n",
    "\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    enhancer = ImageEnhance.Color(image_pil)\n",
    "    saturated_image = enhancer.enhance(factor)\n",
    "    return cv2.cvtColor(np.array(saturated_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def convert_to_artStyle(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a binary threshold\n",
    "    art_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 11, 2)\n",
    "    return art_image\n",
    "\n",
    "def add_noise(image, mean=0, stddev=25):\n",
    "    noise = np.random.normal(mean, stddev, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "def blur_image(image, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c67ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_multiple_choice_task_with_image_augmentation_phi(img_url, question, aug_type=None):\n",
    "     # 下载图片\n",
    "    response = requests.get(img_url)\n",
    "    response.raise_for_status()  # 检查下载是否成功\n",
    "    image = Image.open(BytesIO(response.content))  # 将图片加载到内存中\n",
    "\n",
    "    # Convert the PIL Image to a NumPy array \n",
    "    image = np.array(image)\n",
    "\n",
    "    # Apply image augmentation\n",
    "    if (aug_type is not None):\n",
    "        image = image_augumentation(image, sin_aug = aug_type)[aug_type]  \n",
    "    \n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    images = []\n",
    "    images.append(image)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"<|image_1|>\\n\" + question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "    ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 10, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    generate_ids = model.generate(**inputs, \n",
    "    eos_token_id=processor.tokenizer.eos_token_id, \n",
    "    **generation_args\n",
    "    )\n",
    "\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, \n",
    "    skip_special_tokens=True, \n",
    "    clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34443d2",
   "metadata": {},
   "source": [
    "##### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25cdfc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# apply cropping augmentation\n",
    "df['multiple_choice_prediction_easy_crop_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_easy'], 'crop'), axis=1)\n",
    "df['multiple_choice_prediction_medium_crop_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_medium'], 'crop'), axis=1)\n",
    "df['multiple_choice_prediction_hard_crop_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_hard'], 'crop'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f993e",
   "metadata": {},
   "source": [
    "##### Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4dff9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# apply saturation augmentation\n",
    "df['multiple_choice_prediction_easy_saturation_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_easy'], 'saturation'), axis=1)\n",
    "df['multiple_choice_prediction_medium_saturation_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_medium'], 'saturation'), axis=1)\n",
    "df['multiple_choice_prediction_hard_saturation_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_hard'], 'saturation'), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7b4d5",
   "metadata": {},
   "source": [
    "##### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9767654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# apply noise augmentation\n",
    "df['multiple_choice_prediction_easy_noise_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_easy'], 'noise'), axis=1)\n",
    "df['multiple_choice_prediction_medium_noise_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_medium'], 'noise'), axis=1)\n",
    "df['multiple_choice_prediction_hard_noise_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['url'], x['multiple_choice_question_hard'], 'noise'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94795973",
   "metadata": {},
   "source": [
    "##### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16e0e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties_with_image_augmentation_phi.json\n"
     ]
    }
   ],
   "source": [
    "# Save the MCQ result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties_with_image_augmentation_phi.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f932c",
   "metadata": {},
   "source": [
    "##### Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "691214c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>url</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy_Phi</th>\n",
       "      <th>multiple_choice_prediction_medium_Phi</th>\n",
       "      <th>multiple_choice_prediction_hard_Phi</th>\n",
       "      <th>multiple_choice_prediction_easy_crop_phi</th>\n",
       "      <th>multiple_choice_prediction_medium_crop_phi</th>\n",
       "      <th>multiple_choice_prediction_hard_crop_phi</th>\n",
       "      <th>multiple_choice_prediction_easy_saturation_phi</th>\n",
       "      <th>multiple_choice_prediction_medium_saturation_phi</th>\n",
       "      <th>multiple_choice_prediction_hard_saturation_phi</th>\n",
       "      <th>multiple_choice_prediction_easy_noise_phi</th>\n",
       "      <th>multiple_choice_prediction_medium_noise_phi</th>\n",
       "      <th>multiple_choice_prediction_hard_noise_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512533</td>\n",
       "      <td>COCO_train2014_000000512533.jpg</td>\n",
       "      <td>http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg</td>\n",
       "      <td>[A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]</td>\n",
       "      <td>D</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                        file_name  \\\n",
       "0  512533  COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                       url  \\\n",
       "0  http://images.cocodataset.org/train2014/COCO_train2014_000000512533.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       captions  \\\n",
       "0  [A group of people riding on the back of an elephant., Four people ride on top of an elephant, there are many people that are riding a elephant , A group of people riding on top of a large elephant., Several people sit on top of an elephant as another person watches.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        D   \n",
       "\n",
       "                                                                                                                                                                                                                                                         multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) A group of people riding horses across a field.\\n\\nB) A family having a picnic in a park.\\n\\nC) A group of people rowing a boat on a river.\\n\\nD) A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A group of children playing in a park with a large ball.\\n\\nB. Several tourists sitting inside a colorful hot air balloon.\\n\\nC. A family gathered around a table enjoying dinner together.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "                                                                                                                                                                                                                                                            multiple_choice_question_easy  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. A family having a picnic under a large oak tree.\\n\\nB. A group of friends playing soccer in a park.\\n\\nC. A couple dancing under the stars at a wedding.\\n\\nD. A group of people riding on the back of an elephant.   \n",
       "\n",
       "  multiple_choice_prediction_easy_Phi multiple_choice_prediction_medium_Phi  \\\n",
       "0                                   D                                     D   \n",
       "\n",
       "  multiple_choice_prediction_hard_Phi  \\\n",
       "0                                   D   \n",
       "\n",
       "  multiple_choice_prediction_easy_crop_phi  \\\n",
       "0                                        D   \n",
       "\n",
       "  multiple_choice_prediction_medium_crop_phi  \\\n",
       "0                                          D   \n",
       "\n",
       "  multiple_choice_prediction_hard_crop_phi  \\\n",
       "0                                        D   \n",
       "\n",
       "  multiple_choice_prediction_easy_saturation_phi  \\\n",
       "0                                              D   \n",
       "\n",
       "  multiple_choice_prediction_medium_saturation_phi  \\\n",
       "0                                                D   \n",
       "\n",
       "  multiple_choice_prediction_hard_saturation_phi  \\\n",
       "0                                              D   \n",
       "\n",
       "  multiple_choice_prediction_easy_noise_phi  \\\n",
       "0                                         D   \n",
       "\n",
       "  multiple_choice_prediction_medium_noise_phi  \\\n",
       "0                                           D   \n",
       "\n",
       "  multiple_choice_prediction_hard_noise_phi  \n",
       "0                                         D  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "food_annotation_file_path = '/shared/data/stephen/people_annotation_with_MCQ_result_3_difficulties_with_image_augmentation_phi.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ab52ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy_with_augmentation(df):\n",
    "    # Calculate accuracy\n",
    "\n",
    "    # crop augmentation\n",
    "    accuracy_easy_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_crop_phi\"]).mean()\n",
    "    accuracy_medium_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_crop_phi\"]).mean()\n",
    "    accuracy_hard_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_crop_phi\"]).mean()\n",
    "\n",
    "    # saturation augmentation\n",
    "    accuracy_easy_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_saturation_phi\"]).mean()\n",
    "    accuracy_medium_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_saturation_phi\"]).mean()\n",
    "    accuracy_hard_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_saturation_phi\"]).mean()\n",
    "\n",
    "    # noise augmentation\n",
    "    accuracy_easy_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_noise_phi\"]).mean()\n",
    "    accuracy_medium_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_noise_phi\"]).mean()\n",
    "    accuracy_hard_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_noise_phi\"]).mean()\n",
    "\n",
    "\n",
    "    print('***** Prediction Accuracy with Crop Augmentation *****')\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy_crop * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium_crop * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_crop * 100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    print('***** Prediction Accuracy with Saturation Augmentation *****')\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy_saturation * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium_saturation * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_saturation * 100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    print('***** Prediction Accuracy with Noise Augmentation *****')\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy_noise * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium_noise * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_noise * 100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    return accuracy_easy_crop, accuracy_medium_crop, accuracy_hard_crop, accuracy_easy_saturation, accuracy_medium_saturation, accuracy_hard_saturation, accuracy_easy_noise, accuracy_medium_noise, accuracy_hard_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9fade939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Prediction Accuracy with Crop Augmentation *****\n",
      "Prediction Accuracy Easy: 96.00%\n",
      "Prediction Accuracy Medium: 91.00%\n",
      "Prediction Accuracy Hard: 83.00%\n",
      "\n",
      "\n",
      "***** Prediction Accuracy with Saturation Augmentation *****\n",
      "Prediction Accuracy Easy: 98.00%\n",
      "Prediction Accuracy Medium: 91.00%\n",
      "Prediction Accuracy Hard: 83.00%\n",
      "\n",
      "\n",
      "***** Prediction Accuracy with Noise Augmentation *****\n",
      "Prediction Accuracy Easy: 91.00%\n",
      "Prediction Accuracy Medium: 84.00%\n",
      "Prediction Accuracy Hard: 71.00%\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.96, 0.91, 0.83, 0.98, 0.91, 0.83, 0.91, 0.84, 0.71)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy_with_augmentation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f8f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e33e34b",
   "metadata": {},
   "source": [
    "## ~~Perform Image Captioning Task~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc753d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotation with multiple choice question data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "#food_images_directory = '/shared/data/food_data/food_images/'\n",
    "food_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ee0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_image_captioning_task_llava(img_url):\n",
    "    image = Image.open(img_url)\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": \"Generate a caption for this image.\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    caption = output.split('[/INST]')[1].strip()\n",
    "    print(caption)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510030c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_caption'] = df.apply(lambda x: perform_image_captioning_task_llava(x['img_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['reference_caption', 'predicted_caption']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the image_captioning result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/food_data/food_annotation_with_image_captioning_result.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e19d3d",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104932c",
   "metadata": {},
   "source": [
    "### Multiple Choice Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93141d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "food_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ_result.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_multiple_choice_question_accuracy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff5a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62a7399c",
   "metadata": {},
   "source": [
    "### Caption Quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "food_annotation_file_path = '/shared/data/food_data/food_annotation_with_image_captioning_result.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(food_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "# BLEU Evaluation (Average across multiple references)\n",
    "def evaluate_bleu(df):\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption']  # Predicted caption\n",
    "\n",
    "        # Tokenize the candidate and reference captions\n",
    "        tokenized_references = [ref.strip('\"').split() for ref in references]  # List of tokenized references\n",
    "        tokenized_candidate = candidate.strip('\"').split()  # Tokenized candidate\n",
    "\n",
    "        # Compute BLEU for all references\n",
    "        row_bleu_scores = [\n",
    "            sentence_bleu([ref], tokenized_candidate) for ref in tokenized_references\n",
    "        ]\n",
    "        \n",
    "        # Average across references\n",
    "        bleu_scores.append(sum(row_bleu_scores) / len(row_bleu_scores))\n",
    "    \n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
    "    return bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bleu(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# METEOR Evaluation (Average across multiple references)\n",
    "def evaluate_meteor(df):\n",
    "    meteor_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption'].strip('\"')  # Predicted caption (raw string)\n",
    "\n",
    "        # Compute METEOR for all references\n",
    "        row_meteor_scores = [\n",
    "            meteor_score([[ref]], [candidate]) for ref in references\n",
    "        ]\n",
    "        \n",
    "        # Average across references\n",
    "        meteor_scores.append(sum(row_meteor_scores) / len(row_meteor_scores))\n",
    "    \n",
    "    avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "    print(f\"Average METEOR: {avg_meteor:.4f}\")\n",
    "    return meteor_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_meteor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9438e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE Evaluation (Average across multiple references)\n",
    "def evaluate_rouge(df):\n",
    "    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption']  # Predicted caption\n",
    "        \n",
    "        # Compute ROUGE scores for all references\n",
    "        row_rouge1_scores, row_rouge2_scores, row_rougeL_scores = [], [], []\n",
    "        for ref in references:\n",
    "            scores = scorer.score(ref, candidate.strip('\"'))\n",
    "            row_rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            row_rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            row_rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        \n",
    "        # Average across references\n",
    "        rouge1_scores.append(sum(row_rouge1_scores) / len(row_rouge1_scores))\n",
    "        rouge2_scores.append(sum(row_rouge2_scores) / len(row_rouge2_scores))\n",
    "        rougeL_scores.append(sum(row_rougeL_scores) / len(row_rougeL_scores))\n",
    "    \n",
    "    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
    "    avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
    "    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
    "    \n",
    "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "    print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")\n",
    "    return rouge1_scores, rouge2_scores, rougeL_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rouge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIDEr and SPICE (unchanged, since they handle multiple references internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cider(df):\n",
    "    ref_dict = {str(idx): row['reference_caption'] for idx, row in df.iterrows()}\n",
    "    cand_dict = {str(idx): [row['predicted_caption']] for idx, row in df.iterrows()}\n",
    "    \n",
    "    cider_scorer = Cider()\n",
    "    score, _ = cider_scorer.compute_score(ref_dict, cand_dict)\n",
    "    print(f\"Average CIDEr: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab777ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cider(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618198b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_spice(df):\n",
    "    ref_dict = {str(idx): row['reference_caption'] for idx, row in df.iterrows()}\n",
    "    cand_dict = {str(idx): [row['predicted_caption']] for idx, row in df.iterrows()}\n",
    "    \n",
    "    spice_scorer = Spice()\n",
    "    score, _ = spice_scorer.compute_score(ref_dict, cand_dict)\n",
    "    print(f\"Average SPICE: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_spice(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1614075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
