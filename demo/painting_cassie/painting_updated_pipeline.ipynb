{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aeb58f",
   "metadata": {},
   "source": [
    "## Load Food Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43dd2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbeee77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46323</td>\n",
       "      <td>/shared/data/painting/picts/46323.jpg</td>\n",
       "      <td>[women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              file_path  \\\n",
       "0  46323  /shared/data/painting/picts/46323.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                      captions  \n",
       "0  [women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Directory: \n",
    "# food_images_directory = '/shared/data/food_data/food_images/'\n",
    "upking_annotation_file_path = '/shared/data/painting/paintings.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(upking_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d854959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0458394",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a646505",
   "metadata": {},
   "source": [
    "## Generate Multiple Choice Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad9b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random choice in [A, B, C, D]\n",
    "import random\n",
    "\n",
    "def generate_random_choice():\n",
    "    return random.choice(['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ac2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multiple_choice_solution'] = df.apply(lambda x: generate_random_choice(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4658c508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46323</td>\n",
       "      <td>/shared/data/painting/picts/46323.jpg</td>\n",
       "      <td>[women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63879</td>\n",
       "      <td>/shared/data/painting/picts/63879.jpg</td>\n",
       "      <td>[a group of people is swimming in the ocean, a lot of people in the water are playing and one person with clothes on, a group of people goes for a swim in the sea, the perfect boys are bathing in the sea stock photo, a group of men in the ocean is enjoying a swim]</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13922</td>\n",
       "      <td>/shared/data/painting/picts/13922.jpg</td>\n",
       "      <td>[two people are sitting on a beach with their dog next to them, these two people are enjoying watching the sunset on the beach, a woman is sitting on a bench and someone is sitting on the ground, a woman and a man are sitting on the beach, some individuals are sitting in front of a body of water]</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80041</td>\n",
       "      <td>/shared/data/painting/picts/80041.jpg</td>\n",
       "      <td>[an adult and a child are sitting at the table talking, a man and a woman were playing cards at a table, the woman sitting calmly plays cards with the man, a man and a woman sit opposite each other at the table, a woman hands a man a piece of paper across the table]</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6692</td>\n",
       "      <td>/shared/data/painting/picts/6692.jpg</td>\n",
       "      <td>[a man and a woman are looking at a river in a forest, a man and woman posing in a field by a river, two people out in a wooded area near the water, painters are painting beside a stream, an afternoon in the countryside with a man  ,  a woman  ,  and an easel]</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              file_path  \\\n",
       "0  46323  /shared/data/painting/picts/46323.jpg   \n",
       "1  63879  /shared/data/painting/picts/63879.jpg   \n",
       "2  13922  /shared/data/painting/picts/13922.jpg   \n",
       "3  80041  /shared/data/painting/picts/80041.jpg   \n",
       "4   6692   /shared/data/painting/picts/6692.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    captions  \\\n",
       "0                                                [women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]   \n",
       "1                                   [a group of people is swimming in the ocean, a lot of people in the water are playing and one person with clothes on, a group of people goes for a swim in the sea, the perfect boys are bathing in the sea stock photo, a group of men in the ocean is enjoying a swim]   \n",
       "2  [two people are sitting on a beach with their dog next to them, these two people are enjoying watching the sunset on the beach, a woman is sitting on a bench and someone is sitting on the ground, a woman and a man are sitting on the beach, some individuals are sitting in front of a body of water]   \n",
       "3                                 [an adult and a child are sitting at the table talking, a man and a woman were playing cards at a table, the woman sitting calmly plays cards with the man, a man and a woman sit opposite each other at the table, a woman hands a man a piece of paper across the table]   \n",
       "4                                       [a man and a woman are looking at a river in a forest, a man and woman posing in a field by a river, two people out in a wooded area near the water, painters are painting beside a stream, an afternoon in the countryside with a man  ,  a woman  ,  and an easel]   \n",
       "\n",
       "  multiple_choice_solution  \n",
       "0                        B  \n",
       "1                        C  \n",
       "2                        B  \n",
       "3                        D  \n",
       "4                        D  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b5a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca90e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    ")\n",
    "\n",
    "\n",
    "def generate_multiple_choice_question(reference_caption, correct_choice, level='medium'): \n",
    "    # Define the prompt to generate inferior choices\n",
    "    if level == 'easy':\n",
    "        level_message = \"The distractors are obviously incorrect but still loosely related to the context.\"\n",
    "    elif level == 'medium':\n",
    "        level_message = \"The distractors are somewhat related to the context but contain inaccuracies or non-fluent language.\"\n",
    "    elif level == 'hard':\n",
    "        level_message = \"The distractors are closely related to the context but may confuse someone without careful observation.\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the ground truth caption below:\n",
    "    \"{reference_caption}\"\n",
    "    Generate three plausible but incorrect distractors.\n",
    "    \"{level_message}\"\n",
    "    Format the result as a multiple-choice question. \n",
    "    Question title should be \"Which of the following captions best describes the painting?\".\n",
    "    The correct choice should be placed at choice \"{correct_choice}\". \n",
    "    Do not generate special symbols such as '*'.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "\n",
    "    # Extract the generated multiple-choice question\n",
    "    question = response.choices[0].message.content    \n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007608a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hard question \n",
    "df['multiple_choice_question_hard'] = df.apply(lambda x: generate_multiple_choice_question(x['captions'][0], x['multiple_choice_solution'], level='hard'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fce21b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate medium question\n",
    "df['multiple_choice_question_medium'] = df.apply(lambda x: generate_multiple_choice_question(x['captions'][0], x['multiple_choice_solution'], level='medium'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "933d6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate easy question\n",
    "df['multiple_choice_question_easy'] = df.apply(lambda x: generate_multiple_choice_question(x['captions'][0], x['multiple_choice_solution'], level='easy'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca74bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46323</td>\n",
       "      <td>/shared/data/painting/picts/46323.jpg</td>\n",
       "      <td>[women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]</td>\n",
       "      <td>B</td>\n",
       "      <td>\\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              file_path  \\\n",
       "0  46323  /shared/data/painting/picts/46323.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                      captions  \\\n",
       "0  [women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        B   \n",
       "\n",
       "                                                                                                                                                                                                                                            multiple_choice_question_hard  \\\n",
       "0  \\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.   \n",
       "\n",
       "                                                                                                                                                                                                                                                    multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.   \n",
       "\n",
       "                                                                                                                                                                                                                                                        multiple_choice_question_easy  \n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f1970b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].multiple_choice_question_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d95aed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/painting/paintings_with_MCQ_3diff.json\n"
     ]
    }
   ],
   "source": [
    "# Save the annotation with multiple choice question to output file\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/painting/paintings_with_MCQ_3diff.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057e5631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/upking/upking_annotation_with_MCQ_3diff.json\n"
     ]
    }
   ],
   "source": [
    "# Save the annotation with multiple choice question to output file\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/upking/upking_annotation_with_MCQ_3diff.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ef648",
   "metadata": {},
   "source": [
    "## Perform Multiple Choice Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002b381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46323</td>\n",
       "      <td>/shared/data/painting/picts/46323.jpg</td>\n",
       "      <td>[women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]</td>\n",
       "      <td>B</td>\n",
       "      <td>\\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              file_path  \\\n",
       "0  46323  /shared/data/painting/picts/46323.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                      captions  \\\n",
       "0  [women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        B   \n",
       "\n",
       "                                                                                                                                                                                                                                            multiple_choice_question_hard  \\\n",
       "0  \\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.   \n",
       "\n",
       "                                                                                                                                                                                                                                                    multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.   \n",
       "\n",
       "                                                                                                                                                                                                                                                        multiple_choice_question_easy  \n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "#food_images_directory = '/shared/data/food_data/food_images/'\n",
    "output_file = \"/shared/data/painting/paintings_with_MCQ_3diff.json\"\n",
    "# upking_annotation_file_path = '/shared/data/upking/upking_annotation_with_MCQ.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(output_file)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cbb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f04f522e",
   "metadata": {},
   "source": [
    "### Use llava model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839664b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "import skimage.io as io\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae119ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544d922725c8440e874cf1fc343f117e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model from local directory \n",
    "model_path = '/shared/model/llava-v1.6-mistral-7b-hf'\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(model_path)\n",
    "\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(model_path, torch_dtype=torch.float16, low_cpu_mem_usage=True, load_in_4bit=True) \n",
    "#model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a6480",
   "metadata": {},
   "source": [
    "#### Without image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121f75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_multiple_choice_task_llava(img_path, question):\n",
    "    image = io.imread(img_path)\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # mcq_question = output.split('[/INST]')[0].split('[INST] ')[1].strip()\n",
    "    mcq_answer = output.split('[/INST]')[1].strip()\n",
    "    return mcq_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538636dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_easy'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['file_path'], x['multiple_choice_question_easy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c37dcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     B\n",
       "1     C\n",
       "2     B\n",
       "3     D\n",
       "4     D\n",
       "     ..\n",
       "95    D\n",
       "96    D\n",
       "97    D\n",
       "98    D\n",
       "99    A\n",
       "Name: multiple_choice_prediction_easy, Length: 100, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['multiple_choice_prediction_easy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305ad284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_medium'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['file_path'], x['multiple_choice_question_medium']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf76239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_hard'] = df.apply(lambda x: perform_multiple_choice_task_llava(x['file_path'], x['multiple_choice_question_hard']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0669fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy</th>\n",
       "      <th>multiple_choice_prediction_medium</th>\n",
       "      <th>multiple_choice_prediction_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46323</td>\n",
       "      <td>/shared/data/painting/picts/46323.jpg</td>\n",
       "      <td>[women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]</td>\n",
       "      <td>B</td>\n",
       "      <td>\\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              file_path  \\\n",
       "0  46323  /shared/data/painting/picts/46323.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                      captions  \\\n",
       "0  [women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        B   \n",
       "\n",
       "                                                                                                                                                                                                                                            multiple_choice_question_hard  \\\n",
       "0  \\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.   \n",
       "\n",
       "                                                                                                                                                                                                                                                    multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.   \n",
       "\n",
       "                                                                                                                                                                                                                                                        multiple_choice_question_easy  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.   \n",
       "\n",
       "  multiple_choice_prediction_easy multiple_choice_prediction_medium  \\\n",
       "0                               B                                 A   \n",
       "\n",
       "  multiple_choice_prediction_hard  \n",
       "0                               C  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00ef517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/painting/paintings_with_MCQ_3diff_result.json\n"
     ]
    }
   ],
   "source": [
    "# Save the MCQ result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "# output_file = \"/shared/data/food_data/food_annotation_with_MCQ_result_3_difficulties.json\"\n",
    "output_file = \"/shared/data/painting/paintings_with_MCQ_3diff_result.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f58338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d92dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Easy: 92.00%\n",
      "Prediction Accuracy Medium: 82.00%\n",
      "Prediction Accuracy Hard: 66.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.92, 0.82, 0.66)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74d8cb",
   "metadata": {},
   "source": [
    "#### With Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea73f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will apply the augmentation to the image\n",
    "# sin_aug: single augmentation, includes flip, rotate, crop, saturation, artStyle, noise, blur\n",
    "# mul_aug: multiple augmentations in a list\n",
    "# Return a dictionary. Key: augmentation name; Value: augmented image\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "\n",
    "def image_augumentation(ori_img, sin_aug = None, mul_aug = None):\n",
    "    img = ori_img.copy()\n",
    "    aug_img = {}\n",
    "    if sin_aug:\n",
    "        if sin_aug == 'flip':\n",
    "            aug_img['flip'] = flip_image(img)\n",
    "        elif sin_aug == 'rotate':\n",
    "            aug_img['rotate'] = rotate_image(img)\n",
    "        elif sin_aug == 'crop':\n",
    "            aug_img['crop'] = random_crop(img)\n",
    "        elif sin_aug == 'saturation':\n",
    "            aug_img['saturation'] = adjust_saturation(img)\n",
    "        elif sin_aug == 'artStyle':\n",
    "            aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "        elif sin_aug == 'noise':\n",
    "            aug_img['noise'] = add_noise(img)\n",
    "        elif sin_aug == 'blur':\n",
    "            aug_img['blur'] = blur_image(img)\n",
    "        else:\n",
    "            aug_img['original'] = img\n",
    "\n",
    "    elif mul_aug:\n",
    "        for aug in mul_aug:\n",
    "            if aug == 'flip':\n",
    "                aug_img['flip'] = flip_image(img)\n",
    "            elif aug == 'rotate':\n",
    "                aug_img['rotate'] = rotate_image(img)\n",
    "            elif aug == 'crop':\n",
    "                aug_img['crop'] = random_crop(img)\n",
    "            elif aug == 'saturation':\n",
    "                aug_img['saturation'] = adjust_saturation(img)\n",
    "            elif aug == 'artStyle':\n",
    "                aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "            elif aug == 'noise':\n",
    "                aug_img['noise'] = add_noise(img)\n",
    "            elif aug == 'blur':\n",
    "                aug_img['blur'] = blur_image(img)\n",
    "            else:\n",
    "                aug_img['original'] = img\n",
    "    else:\n",
    "        aug_img['original'] = img\n",
    "    return aug_img\n",
    "\n",
    "def flip_image(image):\n",
    "    img = np.flip(image, axis=1)\n",
    "    return img\n",
    "\n",
    "def rotate_image(image, angle_range=(-30, 30)):\n",
    "    angle = random.uniform(*angle_range)\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "    return rotated_image\n",
    "\n",
    "def random_crop(image, percent=0.7):\n",
    "    h, w = image.shape[:2]\n",
    "    # crop_h, crop_w = crop_size\n",
    "    crop_h = round(percent * h)\n",
    "    crop_w = round(percent * w)\n",
    "\n",
    "    top = random.randint(0, h - crop_h)\n",
    "    left = random.randint(0, w - crop_w)\n",
    "    cropped_image = image[top:top + crop_h, left:left + crop_w]\n",
    "    return cropped_image\n",
    "\n",
    "def adjust_saturation(image, factor=5):\n",
    "\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    enhancer = ImageEnhance.Color(image_pil)\n",
    "    saturated_image = enhancer.enhance(factor)\n",
    "    return cv2.cvtColor(np.array(saturated_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def convert_to_artStyle(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a binary threshold\n",
    "    art_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 11, 2)\n",
    "    return art_image\n",
    "\n",
    "def add_noise(image, mean=0, stddev=25):\n",
    "    noise = np.random.normal(mean, stddev, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "def blur_image(image, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b70ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_multiple_choice_task_with_image_augmentation_llava(img_url, question, aug_type=None):\n",
    "    # image = Image.open(img_url)\n",
    "\n",
    "    # # Convert the PIL Image to a NumPy array\n",
    "    # image = np.array(image)\n",
    "\n",
    "    image = io.imread(img_url)\n",
    "\n",
    "    # Apply image augmentation\n",
    "    if (aug_type is not None):\n",
    "        image = image_augumentation(image, sin_aug = aug_type)[aug_type]  \n",
    "    \n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # mcq_question = output.split('[/INST]')[0].split('[INST] ')[1].strip()\n",
    "    mcq_answer = output.split('[/INST]')[1].strip()\n",
    "    return mcq_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd7d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/shared/data/painting/paintings_with_MCQ_3diff_result.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf05b7a",
   "metadata": {},
   "source": [
    "##### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e02345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Cropping - easy\n",
    "df['multiple_choice_prediction_easy_crop'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_easy'], 'crop'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0866b6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Cropping - medium\n",
    "df['multiple_choice_prediction_medium_crop'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_medium'], 'crop'), axis=1)\n",
    "# Cropping - hard\n",
    "df['multiple_choice_prediction_hard_crop'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_hard'], 'crop'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e586c",
   "metadata": {},
   "source": [
    "##### saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80044e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Saturation - easy\n",
    "# df['multiple_choice_prediction_easy_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_easy'], 'saturation'), axis=1)\n",
    "# Saturation - medium\n",
    "# df['multiple_choice_prediction_medium_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_medium'], 'saturation'), axis=1)\n",
    "# Saturation - hard\n",
    "df['multiple_choice_prediction_hard_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_hard'], 'saturation'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multiple_choice_prediction_medium_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_medium'], 'saturation'), axis=1)\n",
    "# # Saturation - hard\n",
    "# df['multiple_choice_prediction_hard_saturation'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_hard'], 'saturation'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bcc7a",
   "metadata": {},
   "source": [
    "##### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f885e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Noise - easy\n",
    "# df['multiple_choice_prediction_easy_noise'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_easy'], 'noise'), axis=1)\n",
    "# Noise - medium\n",
    "# df['multiple_choice_prediction_medium_noise'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_medium'], 'noise'), axis=1)\n",
    "# # Noise - hard\n",
    "df['multiple_choice_prediction_hard_noise'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_llava(x['file_path'], x['multiple_choice_question_hard'], 'noise'), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c9f5d",
   "metadata": {},
   "source": [
    "##### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30e4a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/painting/paintings_with_MCQ_3diff_result_augmentation.json\n"
     ]
    }
   ],
   "source": [
    "# Save the MCQ result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/painting/paintings_with_MCQ_3diff_result_augmentation.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36641ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8394b836",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccfbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy_crop</th>\n",
       "      <th>multiple_choice_prediction_medium_crop</th>\n",
       "      <th>multiple_choice_prediction_hard_crop</th>\n",
       "      <th>multiple_choice_prediction_easy_saturation</th>\n",
       "      <th>multiple_choice_prediction_medium_saturation</th>\n",
       "      <th>multiple_choice_prediction_hard_saturation</th>\n",
       "      <th>multiple_choice_prediction_easy_noise</th>\n",
       "      <th>multiple_choice_prediction_medium_noise</th>\n",
       "      <th>multiple_choice_prediction_hard_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      multiple_choice_question_hard  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole, uncooked pork rib.\\n\\nC. On the wooden chopping board, there is a cut up grilled and cooked chicken breast.\\n\\nD. On the wooden chopping board, there is a sliced loaf of bread.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                             multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden table, there is a whole raw pork rib with sauce.\\n\\nC. On the wooden chopping board, a raw fish is being sliced in half.\\n\\nD. On the chopping board, there is a grilled chicken leg with vegetables.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 multiple_choice_question_easy  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB. On the wooden chopping board, there is a whole raw fish ready to be cooked.\\n\\nC. On the wooden chopping board, there is a freshly baked loaf of bread.\\n\\nD. On the wooden chopping board, there is a colorful assortment of fresh fruits.   \n",
       "\n",
       "  multiple_choice_prediction_easy_crop multiple_choice_prediction_medium_crop  \\\n",
       "0                                    A                                      A   \n",
       "\n",
       "  multiple_choice_prediction_hard_crop  \\\n",
       "0                                    A   \n",
       "\n",
       "  multiple_choice_prediction_easy_saturation  \\\n",
       "0                                          A   \n",
       "\n",
       "  multiple_choice_prediction_medium_saturation  \\\n",
       "0                                            A   \n",
       "\n",
       "  multiple_choice_prediction_hard_saturation  \\\n",
       "0                                          A   \n",
       "\n",
       "  multiple_choice_prediction_easy_noise  \\\n",
       "0                                     A   \n",
       "\n",
       "  multiple_choice_prediction_medium_noise  \\\n",
       "0                                       A   \n",
       "\n",
       "  multiple_choice_prediction_hard_noise  \n",
       "0                                     A  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "upking_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ_result_3_difficulties_with_image_augmentation.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(upking_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e422b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy_with_augmentation(df):\n",
    "    # Calculate accuracy\n",
    "\n",
    "    # crop augmentation\n",
    "    # accuracy_easy_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_crop\"]).mean()\n",
    "    # accuracy_medium_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_crop\"]).mean()\n",
    "    # accuracy_hard_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_crop\"]).mean()\n",
    "\n",
    "    # # saturation augmentation\n",
    "    # accuracy_easy_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_saturation\"]).mean()\n",
    "    # accuracy_medium_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_saturation\"]).mean()\n",
    "    # accuracy_hard_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_saturation\"]).mean()\n",
    "\n",
    "    # # noise augmentation\n",
    "    # accuracy_easy_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_noise\"]).mean()\n",
    "    # accuracy_medium_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_noise\"]).mean()\n",
    "    accuracy_hard_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_noise\"]).mean()\n",
    "\n",
    "\n",
    "    # print('***** Prediction Accuracy with Crop Augmentation *****')\n",
    "    # print(f\"Prediction Accuracy Easy: {accuracy_easy_crop * 100:.2f}%\") \n",
    "    # print(f\"Prediction Accuracy Medium: {accuracy_medium_crop * 100:.2f}%\")\n",
    "    # print(f\"Prediction Accuracy Hard: {accuracy_hard_crop * 100:.2f}%\")\n",
    "\n",
    "    # print('***** Prediction Accuracy with Saturation Augmentation *****')\n",
    "    # print(f\"Prediction Accuracy Easy: {accuracy_easy_saturation * 100:.2f}%\")\n",
    "    # print(f\"Prediction Accuracy Medium: {accuracy_medium_saturation * 100:.2f}%\")\n",
    "    # print(f\"Prediction Accuracy Hard: {accuracy_hard_saturation * 100:.2f}%\")\n",
    "\n",
    "    print('***** Prediction Accuracy with Noise Augmentation *****')\n",
    "    # print(f\"Prediction Accuracy Easy: {accuracy_easy_noise * 100:.2f}%\")\n",
    "    # print(f\"Prediction Accuracy Medium: {accuracy_medium_noise * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_noise * 100:.2f}%\")\n",
    "\n",
    "    return accuracy_hard_noise\n",
    "    return accuracy_easy_crop, accuracy_medium_crop, accuracy_hard_crop, accuracy_easy_saturation, accuracy_medium_saturation, accuracy_hard_saturation, accuracy_easy_noise, accuracy_medium_noise, accuracy_hard_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "351e53c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Prediction Accuracy with Noise Augmentation *****\n",
      "Prediction Accuracy Hard: 59.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy_with_augmentation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268f406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c76059fa",
   "metadata": {},
   "source": [
    "### Use Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca27531e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy</th>\n",
       "      <th>multiple_choice_prediction_medium</th>\n",
       "      <th>multiple_choice_prediction_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46323</td>\n",
       "      <td>/shared/data/painting/picts/46323.jpg</td>\n",
       "      <td>[women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]</td>\n",
       "      <td>B</td>\n",
       "      <td>\\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              file_path  \\\n",
       "0  46323  /shared/data/painting/picts/46323.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                      captions  \\\n",
       "0  [women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        B   \n",
       "\n",
       "                                                                                                                                                                                                                                            multiple_choice_question_hard  \\\n",
       "0  \\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.   \n",
       "\n",
       "                                                                                                                                                                                                                                                    multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.   \n",
       "\n",
       "                                                                                                                                                                                                                                                        multiple_choice_question_easy  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.   \n",
       "\n",
       "  multiple_choice_prediction_easy multiple_choice_prediction_medium  \\\n",
       "0                               B                                 A   \n",
       "\n",
       "  multiple_choice_prediction_hard  \n",
       "0                               C  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load question dataframe\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "# Data Directory: \n",
    "upking_annotation_file_path = '/shared/data/painting/paintings_with_MCQ_3diff_result.json'\n",
    "\n",
    "df = pd.read_json(upking_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2261f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47b83fea77749c9a4740f359d7b2a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:520: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoProcessor \n",
    "\n",
    "model_id = \"/shared/model/Phi-3.5-vision-instruct\" \n",
    "\n",
    "# Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_id, \n",
    "  device_map=\"cuda\", \n",
    "  trust_remote_code=True, \n",
    "  torch_dtype=\"auto\", \n",
    "  _attn_implementation='eager'    \n",
    ")\n",
    "\n",
    "# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "processor = AutoProcessor.from_pretrained(model_id, \n",
    "  trust_remote_code=True, \n",
    "  num_crops=4\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8ed8b",
   "metadata": {},
   "source": [
    "#### Without image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea59df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_multiple_choice_task_Phi(img_url, question):\n",
    "    image = Image.open(img_url)\n",
    "\n",
    "    images = []\n",
    "    images.append(image)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"<|image_1|>\\n\" + question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "    ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 10, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    generate_ids = model.generate(**inputs, \n",
    "    eos_token_id=processor.tokenizer.eos_token_id, \n",
    "    **generation_args\n",
    "    )\n",
    "\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, \n",
    "    skip_special_tokens=True, \n",
    "    clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3510fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/painting/paintings_with_MCQ_3diff_result_augmentation_phi.json\n"
     ]
    }
   ],
   "source": [
    "# Save the annotation with multiple choice question to output file\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/painting/paintings_with_MCQ_3diff_result_augmentation_phi.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "628bf7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "WARNING:transformers_modules.Phi-3.5-vision-instruct.modeling_phi3_v:You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_easy_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['file_path'], x['multiple_choice_question_easy']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bb2ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_medium_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['file_path'], x['multiple_choice_question_medium']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1926fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['multiple_choice_prediction_hard_Phi'] = df.apply(lambda x: perform_multiple_choice_task_Phi(x['file_path'], x['multiple_choice_question_hard']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0432e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the prediction results to output file\n",
    "# # Convert DataFrame to a list of dictionaries\n",
    "# list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# # Save the list of dictionaries to a JSON file\n",
    "# output_file = \"llava_prediction_result_food_image.json\"\n",
    "# with open(output_file, \"w\") as file:\n",
    "#     json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "# print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75a388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "def calculate_multiple_choice_question_accuracy_Phi(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_Phi\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_Phi\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_Phi\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a472fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Easy: 91.00%\n",
      "Prediction Accuracy Medium: 81.00%\n",
      "Prediction Accuracy Hard: 72.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.91, 0.81, 0.72)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy_Phi(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3acb58",
   "metadata": {},
   "source": [
    "#### With Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ccad6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will apply the augmentation to the image\n",
    "# sin_aug: single augmentation, includes flip, rotate, crop, saturation, artStyle, noise, blur\n",
    "# mul_aug: multiple augmentations in a list\n",
    "# Return a dictionary. Key: augmentation name; Value: augmented image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "\n",
    "def image_augumentation(ori_img, sin_aug = None, mul_aug = None):\n",
    "    img = ori_img.copy()\n",
    "    aug_img = {}\n",
    "    if sin_aug:\n",
    "        if sin_aug == 'flip':\n",
    "            aug_img['flip'] = flip_image(img)\n",
    "        elif sin_aug == 'rotate':\n",
    "            aug_img['rotate'] = rotate_image(img)\n",
    "        elif sin_aug == 'crop':\n",
    "            aug_img['crop'] = random_crop(img)\n",
    "        elif sin_aug == 'saturation':\n",
    "            aug_img['saturation'] = adjust_saturation(img)\n",
    "        elif sin_aug == 'artStyle':\n",
    "            aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "        elif sin_aug == 'noise':\n",
    "            aug_img['noise'] = add_noise(img)\n",
    "        elif sin_aug == 'blur':\n",
    "            aug_img['blur'] = blur_image(img)\n",
    "        else:\n",
    "            aug_img['original'] = img\n",
    "\n",
    "    elif mul_aug:\n",
    "        for aug in mul_aug:\n",
    "            if aug == 'flip':\n",
    "                aug_img['flip'] = flip_image(img)\n",
    "            elif aug == 'rotate':\n",
    "                aug_img['rotate'] = rotate_image(img)\n",
    "            elif aug == 'crop':\n",
    "                aug_img['crop'] = random_crop(img)\n",
    "            elif aug == 'saturation':\n",
    "                aug_img['saturation'] = adjust_saturation(img)\n",
    "            elif aug == 'artStyle':\n",
    "                aug_img['artStyle'] = convert_to_artStyle(img)\n",
    "            elif aug == 'noise':\n",
    "                aug_img['noise'] = add_noise(img)\n",
    "            elif aug == 'blur':\n",
    "                aug_img['blur'] = blur_image(img)\n",
    "            else:\n",
    "                aug_img['original'] = img\n",
    "    else:\n",
    "        aug_img['original'] = img\n",
    "    return aug_img\n",
    "\n",
    "def flip_image(image):\n",
    "    img = np.flip(image, axis=1)\n",
    "    return img\n",
    "\n",
    "def rotate_image(image, angle_range=(-30, 30)):\n",
    "    angle = random.uniform(*angle_range)\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "    return rotated_image\n",
    "\n",
    "def random_crop(image, percent=0.7):\n",
    "    h, w = image.shape[:2]\n",
    "    # crop_h, crop_w = crop_size\n",
    "    crop_h = round(percent * h)\n",
    "    crop_w = round(percent * w)\n",
    "\n",
    "    top = random.randint(0, h - crop_h)\n",
    "    left = random.randint(0, w - crop_w)\n",
    "    cropped_image = image[top:top + crop_h, left:left + crop_w]\n",
    "    return cropped_image\n",
    "\n",
    "def adjust_saturation(image, factor=5):\n",
    "\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    enhancer = ImageEnhance.Color(image_pil)\n",
    "    saturated_image = enhancer.enhance(factor)\n",
    "    return cv2.cvtColor(np.array(saturated_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def convert_to_artStyle(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a binary threshold\n",
    "    art_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 11, 2)\n",
    "    return art_image\n",
    "\n",
    "def add_noise(image, mean=0, stddev=25):\n",
    "    noise = np.random.normal(mean, stddev, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "def blur_image(image, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c67ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_multiple_choice_task_with_image_augmentation_phi(img_url, question, aug_type=None):\n",
    "    image = Image.open(img_url)\n",
    "\n",
    "    # Convert the PIL Image to a NumPy array \n",
    "    image = np.array(image)\n",
    "\n",
    "    # Apply image augmentation\n",
    "    if (aug_type is not None):\n",
    "        image = image_augumentation(image, sin_aug = aug_type)[aug_type]  \n",
    "    \n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    images = []\n",
    "    images.append(image)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"<|image_1|>\\n\" + question + \"\\nOnly return the correct choice with a single letter.\"},\n",
    "    ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 10, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    generate_ids = model.generate(**inputs, \n",
    "    eos_token_id=processor.tokenizer.eos_token_id, \n",
    "    **generation_args\n",
    "    )\n",
    "\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, \n",
    "    skip_special_tokens=True, \n",
    "    clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34443d2",
   "metadata": {},
   "source": [
    "##### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25cdfc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# apply cropping augmentation\n",
    "df['multiple_choice_prediction_easy_crop_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_easy'], 'crop'), axis=1)\n",
    "df['multiple_choice_prediction_medium_crop_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_medium'], 'crop'), axis=1)\n",
    "df['multiple_choice_prediction_hard_crop_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_hard'], 'crop'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f993e",
   "metadata": {},
   "source": [
    "##### Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4dff9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# apply saturation augmentation\n",
    "df['multiple_choice_prediction_easy_saturation_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_easy'], 'saturation'), axis=1)\n",
    "df['multiple_choice_prediction_medium_saturation_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_medium'], 'saturation'), axis=1)\n",
    "df['multiple_choice_prediction_hard_saturation_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_hard'], 'saturation'), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7b4d5",
   "metadata": {},
   "source": [
    "##### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9767654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# apply noise augmentation\n",
    "df['multiple_choice_prediction_easy_noise_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_easy'], 'noise'), axis=1)\n",
    "df['multiple_choice_prediction_medium_noise_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_medium'], 'noise'), axis=1)\n",
    "df['multiple_choice_prediction_hard_noise_phi'] = df.apply(lambda x: perform_multiple_choice_task_with_image_augmentation_phi(x['file_path'], x['multiple_choice_question_hard'], 'noise'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94795973",
   "metadata": {},
   "source": [
    "##### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e0e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/food_data/food_annotation_with_MCQ_result_3_difficulties_with_image_augmentation_phi.json\n"
     ]
    }
   ],
   "source": [
    "# Save the MCQ result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/food_data/food_annotation_with_MCQ_result_3_difficulties_with_image_augmentation_phi.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f932c",
   "metadata": {},
   "source": [
    "##### Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691214c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "upking_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ_result_3_difficulties_with_image_augmentation_phi.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(upking_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ab52ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy_with_augmentation(df):\n",
    "    # Calculate accuracy\n",
    "\n",
    "    # crop augmentation\n",
    "    # accuracy_easy_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_crop_phi\"]).mean()\n",
    "    # accuracy_medium_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_crop_phi\"]).mean()\n",
    "    # accuracy_hard_crop = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_crop_phi\"]).mean()\n",
    "\n",
    "    # # saturation augmentation\n",
    "    # accuracy_easy_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_saturation_phi\"]).mean()\n",
    "    # accuracy_medium_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_saturation_phi\"]).mean()\n",
    "    # accuracy_hard_saturation = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_saturation_phi\"]).mean()\n",
    "\n",
    "    # noise augmentation\n",
    "    accuracy_easy_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy_noise_phi\"]).mean()\n",
    "    accuracy_medium_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium_noise_phi\"]).mean()\n",
    "    accuracy_hard_noise = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard_noise_phi\"]).mean()\n",
    "\n",
    "\n",
    "    # print('***** Prediction Accuracy with Crop Augmentation *****')\n",
    "    # print(f\"Prediction Accuracy Easy: {accuracy_easy_crop * 100:.2f}%\") \n",
    "    # print(f\"Prediction Accuracy Medium: {accuracy_medium_crop * 100:.2f}%\")\n",
    "    # print(f\"Prediction Accuracy Hard: {accuracy_hard_crop * 100:.2f}%\")\n",
    "    # print('\\n')\n",
    "\n",
    "    # print('***** Prediction Accuracy with Saturation Augmentation *****')\n",
    "    # print(f\"Prediction Accuracy Easy: {accuracy_easy_saturation * 100:.2f}%\")\n",
    "    # print(f\"Prediction Accuracy Medium: {accuracy_medium_saturation * 100:.2f}%\")\n",
    "    # print(f\"Prediction Accuracy Hard: {accuracy_hard_saturation * 100:.2f}%\")\n",
    "    # print('\\n')\n",
    "\n",
    "    print('***** Prediction Accuracy with Noise Augmentation *****')\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy_noise * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium_noise * 100:.2f}%\")\n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard_noise * 100:.2f}%\")\n",
    "    print('\\n')\n",
    "\n",
    "    return accuracy_easy_noise, accuracy_medium_noise, accuracy_hard_noise\n",
    "    return accuracy_easy_crop, accuracy_medium_crop, accuracy_hard_crop, accuracy_easy_saturation, accuracy_medium_saturation, accuracy_hard_saturation, accuracy_easy_noise, accuracy_medium_noise, accuracy_hard_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fade939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Prediction Accuracy with Noise Augmentation *****\n",
      "Prediction Accuracy Easy: 80.00%\n",
      "Prediction Accuracy Medium: 70.00%\n",
      "Prediction Accuracy Hard: 62.00%\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8, 0.7, 0.62)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy_with_augmentation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f8f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e33e34b",
   "metadata": {},
   "source": [
    "## ~~Perform Image Captioning Task~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc753d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                   multiple_choice_question  \n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "#food_images_directory = '/shared/data/food_data/food_images/'\n",
    "upking_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(upking_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b51ee0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: \n",
    "def perform_image_captioning_task_llava(img_url):\n",
    "    image = Image.open(img_url)\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": \"Generate a caption for this image.\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    output = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    caption = output.split('[/INST]')[1].strip()\n",
    "    print(caption)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "510030c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the moment before the feast begins.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the flavors of a succulent barbecue ribs feast.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the smoky, savory flavor of a perfectly grilled rib.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the flavors of a succulent barbecue ribs meal.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of succulent ribs, crispy potatoes, and a refreshing can of soda.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the taste of a succulent BBQ rib, garnished with fresh herbs and a tangy sauce, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the flavors of a succulent barbecue rib.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the moment before the feast begins.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savoring the taste of a delicious, crispy snack.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of succulent meat and creamy beans, served on a rustic wooden table.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful treat, a slice of cake with a dusting of powdered sugar, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful plate of crispy, golden-brown fried dumplings, garnished with a sprinkle of sugar and served with a refreshing slice of orange.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of freshly baked pastries, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful breakfast spread featuring a stack of golden pancakes, a glass of refreshing milk, and a side of fluffy donuts.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of sweet treats, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful trio of golden brown dumplings, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A tantalizing treat, a sugar-coated doughnut, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of powdered sugar-covered pastries, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful treat: powdered sugar-covered pastries on a plate, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful assortment of freshly baked pastries, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious seafood stir fry with noodles and a variety of ingredients.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp noodle soup, ready to warm up a chilly day!\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp noodle soup, garnished with a soft-boiled egg and fresh herbs, ready to warm the soul.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of seafood noodle soup, ready to warm the soul.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty seafood dish, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of noodles, seafood, and greens, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious and colorful meal of noodles, seafood, and a side of soup, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp noodle soup, ready to warm the soul on a chilly day.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of noodles, topped with succulent meat and garnished with a sprinkle of sesame seeds.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty bowl of shrimp and noodle soup, filled with vibrant colors and flavors.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and beans, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and beans, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and beans, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and greens, served in a rustic cast iron skillet.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and beans, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage and pasta, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausage, potatoes, and a side of fresh vegetables.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Preparing a hearty meal with freshly chopped ginger root and a sharp knife.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and pasta, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of sausages and onions, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary experience awaits with these skewered delights, garnished with a touch of elegance.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary scene featuring freshly made dough balls, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A colorful culinary adventure: Five mini pizzas, each with its own unique toppings, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant red dish filled with freshly sliced white radishes, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful stack of crispy, golden-brown pancakes, topped with a dollop of creamy peanut butter, served on a charming blue and white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary experience featuring a trio of golden-brown, crispy tofu squares, garnished with a sprig of fresh green herbs, served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A moment of culinary artistry: freshly grated parmesan cheese being added to a dish.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful snack of apple slices and peanut butter on a bed of crunchy rice cakes.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of sushi with a vibrant green seaweed topping, resting on a textured surface.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of avocado toast topped with a sprinkle of sprouts and a drizzle of creamy sauce, served on a rustic wooden table.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful sushi meal, complete with a refreshing drink and a side of spices.\"\n",
      "\"A delightful culinary experience awaits with these two mouth-watering sushi rolls, each meticulously crafted and ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A colorful and appetizing bento box, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful plate of sushi rolls, garnished with a sprinkle of sesame seeds and a drizzle of soy sauce, ready to be savored.\"\n",
      "\"A delightful bite of sushi rice, topped with a slice of seaweed, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious and healthy meal, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful snack of sushi rice balls, topped with a vibrant orange filling, served on a white plate with a side of soy sauce.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful sushi dish, served on a black plate with a touch of orange, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful plate of sushi rolls, garnished with sesame seeds and green onions, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A culinary delight: Japanese onigiri, meticulously crafted with a sprinkle of spice.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful medley of fresh fruits and a flaky pastry, perfect for a summer afternoon.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: a delicious piece of pie on a gold plate, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A creamy cheesecake with a golden crust, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: a delicious dessert with a hint of citrus.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A stack of golden, flaky waffles topped with a dollop of whipped cream and a slice of lemon, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A perfectly baked pie with a flaky crust, topped with a scoop of vanilla ice cream, all ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dessert scene featuring a slice of lemon meringue pie, a scoop of ice cream, and a sprinkle of powdered sugar, all served on a charming blue plate with a yellow checkered napkin.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A tantalizing dessert with a golden crust and a fluffy meringue topping.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A delicious, creamy slice of lemon meringue pie.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of heaven: A delicious dessert served on a fine china plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious meal of sliced chicken with a side of flavorful sauce, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of tender, succulent chicken pieces, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful meal of succulent chicken in a vibrant sauce, served on a traditional blue and white plate, accompanied by a refreshing side of soup.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delicious and hearty meal of chicken and broccoli in a savory sauce, garnished with a sprig of parsley and a purple flower, served on a bamboo placemat.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of crispy, golden-brown fried chicken, served on a pristine white plate, garnished with a sprig of parsley and a vibrant purple flower, ready to be savored.\"\n",
      "\"A tantalizing dish of succulent chicken, garnished with a vibrant red tomato and a sprig of fresh parsley, served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dish of roasted chicken, garnished with a sprig of parsley and a purple flower, served on a white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A tantalizing dish of succulent pork belly, served with a side of vibrant green onions, all presented on a rustic wooden table.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful culinary experience featuring succulent chicken and fresh herbs, served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful meal of succulent chicken, fresh carrots, and aromatic parsley, all served on a pristine white plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and healthy Mediterranean-style salad, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful Mediterranean feast, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and appetizing meal, ready to be savored!\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and healthy salad, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful spread of appetizers, ready to be savored.\"\n",
      "\"A vibrant salad of fresh tomatoes, crisp lettuce, and creamy cheese, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant medley of fresh vegetables and crumbled feta cheese, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant and healthy salad, bursting with fresh vegetables and a sprinkle of feta cheese.\"\n",
      "\"A vibrant medley of fresh vegetables and juicy tomatoes, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A vibrant salad, bursting with colors and flavors.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A delightful dessert moment captured on a floral-patterned plate.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Homemade pie cooling on the stove, ready to be served.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A cozy meal of comfort food, featuring a hearty casserole and a side of fresh greens.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A tantalizing view of a pecan pie, freshly baked and ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of delicious pie, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A hearty meal of a classic shepherd's pie, topped with a golden crust and served with a side of creamy baked beans.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A slice of pie, ready to be savored.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A freshly baked pie, ready to be enjoyed.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A golden-brown pie crust, ready for a delicious filling.\"\n",
      "\"A delicious, homemade pizza, freshly baked and ready to be enjoyed.\"\n"
     ]
    }
   ],
   "source": [
    "df['predicted_caption'] = df.apply(lambda x: perform_image_captioning_task_llava(x['img_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc9f48f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>predicted_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>\"Savoring the moment before the feast begins.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Many grilled pork ribs are arranged in a curiously shaped wooden cutlery.]</td>\n",
       "      <td>\"Savoring the flavors of a succulent barbecue ribs feast.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Two grilled brown-red pork ribs on an oval white dinner plate.]</td>\n",
       "      <td>\"Savoring the smoky, savory flavor of a perfectly grilled rib.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Three pork ribs drizzled with a rich sauce and served on a white round dinner plate.]</td>\n",
       "      <td>\"Savoring the flavors of a succulent barbecue ribs meal.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Raw, long, fresh pork ribs next to yellow, good potatoes.]</td>\n",
       "      <td>\"A hearty meal of succulent ribs, crispy potatoes, and a refreshing can of soda.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[A golden bean pie and some pork fried soybeans on a white round plate]</td>\n",
       "      <td>\"A hearty meal of a classic shepherd's pie, topped with a golden crust and served with a side of creamy baked beans.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[A plate of bean pie with a yellow edge and orange skin, and a napkin, a fork, and a knife next to it.]</td>\n",
       "      <td>\"A slice of pie, ready to be savored.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[A dark brown bean pie with a golden edge on a tray placed on a stainless steel net.]</td>\n",
       "      <td>\"A freshly baked pie, ready to be enjoyed.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[a bean pie with scratches on the crispy surface which is caramel color fading from the edge to the center.]</td>\n",
       "      <td>\"A golden-brown pie crust, ready for a delicious filling.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[a baked pie made of beans covered with coriander put on a green plate with a floral border.]</td>\n",
       "      <td>\"A delicious, homemade pizza, freshly baked and ready to be enjoyed.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               reference_caption  \\\n",
       "0                                 [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "1                                    [Many grilled pork ribs are arranged in a curiously shaped wooden cutlery.]   \n",
       "2                                               [Two grilled brown-red pork ribs on an oval white dinner plate.]   \n",
       "3                         [Three pork ribs drizzled with a rich sauce and served on a white round dinner plate.]   \n",
       "4                                                    [Raw, long, fresh pork ribs next to yellow, good potatoes.]   \n",
       "..                                                                                                           ...   \n",
       "95                                       [A golden bean pie and some pork fried soybeans on a white round plate]   \n",
       "96       [A plate of bean pie with a yellow edge and orange skin, and a napkin, a fork, and a knife next to it.]   \n",
       "97                         [A dark brown bean pie with a golden edge on a tray placed on a stainless steel net.]   \n",
       "98  [a bean pie with scratches on the crispy surface which is caramel color fading from the edge to the center.]   \n",
       "99                 [a baked pie made of beans covered with coriander put on a green plate with a floral border.]   \n",
       "\n",
       "                                                                                                        predicted_caption  \n",
       "0                                                                          \"Savoring the moment before the feast begins.\"  \n",
       "1                                                              \"Savoring the flavors of a succulent barbecue ribs feast.\"  \n",
       "2                                                         \"Savoring the smoky, savory flavor of a perfectly grilled rib.\"  \n",
       "3                                                               \"Savoring the flavors of a succulent barbecue ribs meal.\"  \n",
       "4                                       \"A hearty meal of succulent ribs, crispy potatoes, and a refreshing can of soda.\"  \n",
       "..                                                                                                                    ...  \n",
       "95  \"A hearty meal of a classic shepherd's pie, topped with a golden crust and served with a side of creamy baked beans.\"  \n",
       "96                                                                                 \"A slice of pie, ready to be savored.\"  \n",
       "97                                                                            \"A freshly baked pie, ready to be enjoyed.\"  \n",
       "98                                                             \"A golden-brown pie crust, ready for a delicious filling.\"  \n",
       "99                                                  \"A delicious, homemade pizza, freshly baked and ready to be enjoyed.\"  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['reference_caption', 'predicted_caption']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0f3de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as a list of dictionaries in /shared/data/food_data/food_annotation_with_image_captioning_result.json\n"
     ]
    }
   ],
   "source": [
    "# Save the image_captioning result\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "list_of_dicts = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "output_file = \"/shared/data/food_data/food_annotation_with_image_captioning_result.json\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(list_of_dicts, file, indent=4)\n",
    "\n",
    "print(f\"DataFrame saved as a list of dictionaries in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e19d3d",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae28d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104932c",
   "metadata": {},
   "source": [
    "### Multiple Choice Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93141d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question</th>\n",
       "      <th>multiple_choice_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg</td>\n",
       "      <td>[On the wooden chopping board, there is a cut up grilled and cooked pork rib.]</td>\n",
       "      <td>A</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                          img_url  \\\n",
       "0   1  /shared/data/food_data/food_images/Pork_ribs/Pork_ribs_0094.jpg   \n",
       "\n",
       "                                                                reference_caption  \\\n",
       "0  [On the wooden chopping board, there is a cut up grilled and cooked pork rib.]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        A   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                   multiple_choice_question  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA) On the wooden chopping board, there is a cut up grilled and cooked pork rib.\\n\\nB) On the wooden cutting board, there is a raw fish and some vegetables.\\n\\nC) The wooden chopping board having a sliced beef steak on it.\\n\\nD) On the wooden table, there is a whole roasted chicken with side of greens.   \n",
       "\n",
       "  multiple_choice_prediction  \n",
       "0                          A  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "upking_annotation_file_path = '/shared/data/food_data/food_annotation_with_MCQ_result.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(upking_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32a0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multiple_choice_question_accuracy(df):\n",
    "    # Calculate accuracy\n",
    "    accuracy_easy = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_easy\"]).mean()\n",
    "    accuracy_medium = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_medium\"]).mean()\n",
    "    accuracy_hard = (df[\"multiple_choice_solution\"] == df[\"multiple_choice_prediction_hard\"]).mean()\n",
    "\n",
    "    print(f\"Prediction Accuracy Easy: {accuracy_easy * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Medium: {accuracy_medium * 100:.2f}%\") \n",
    "    print(f\"Prediction Accuracy Hard: {accuracy_hard * 100:.2f}%\") \n",
    "    return accuracy_easy, accuracy_medium, accuracy_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02acaf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Easy: 94.00%\n",
      "Prediction Accuracy Medium: 71.00%\n",
      "Prediction Accuracy Hard: 63.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94, 0.71, 0.63)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_multiple_choice_question_accuracy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff5a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62a7399c",
   "metadata": {},
   "source": [
    "### Caption Quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e8d555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>captions</th>\n",
       "      <th>multiple_choice_solution</th>\n",
       "      <th>multiple_choice_question_hard</th>\n",
       "      <th>multiple_choice_question_medium</th>\n",
       "      <th>multiple_choice_question_easy</th>\n",
       "      <th>multiple_choice_prediction_easy</th>\n",
       "      <th>multiple_choice_prediction_medium</th>\n",
       "      <th>multiple_choice_prediction_hard</th>\n",
       "      <th>...</th>\n",
       "      <th>multiple_choice_prediction_hard_Phi</th>\n",
       "      <th>multiple_choice_prediction_easy_crop_phi</th>\n",
       "      <th>multiple_choice_prediction_medium_crop_phi</th>\n",
       "      <th>multiple_choice_prediction_hard_crop_phi</th>\n",
       "      <th>multiple_choice_prediction_easy_saturation_phi</th>\n",
       "      <th>multiple_choice_prediction_medium_saturation_phi</th>\n",
       "      <th>multiple_choice_prediction_hard_saturation_phi</th>\n",
       "      <th>multiple_choice_prediction_easy_noise_phi</th>\n",
       "      <th>multiple_choice_prediction_medium_noise_phi</th>\n",
       "      <th>multiple_choice_prediction_hard_noise_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46323</td>\n",
       "      <td>/shared/data/painting/picts/46323.jpg</td>\n",
       "      <td>[women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]</td>\n",
       "      <td>B</td>\n",
       "      <td>\\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.</td>\n",
       "      <td>Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.</td>\n",
       "      <td>Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              file_path  \\\n",
       "0  46323  /shared/data/painting/picts/46323.jpg   \n",
       "\n",
       "                                                                                                                                                                                                                                                      captions  \\\n",
       "0  [women are bent over a river 's edge  ,  doing laundry, it is wash day at the edge of the river for these women, women are washing clothes by the river, women in rustic clothing are lined up along the bank of a river, people are kneeling near a shore]   \n",
       "\n",
       "  multiple_choice_solution  \\\n",
       "0                        B   \n",
       "\n",
       "                                                                                                                                                                                                                                            multiple_choice_question_hard  \\\n",
       "0  \\nWhich of the following captions best describes the painting?\\n\\nA. Women are fishing by the river's edge.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are gathering water from the river.\\n\\nD. Women are having a picnic by the riverside.   \n",
       "\n",
       "                                                                                                                                                                                                                                                    multiple_choice_question_medium  \\\n",
       "0  Which of the following captions best describes the painting?\\n\\nA. Women are standing by a lake, catching fish.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are sitting by a river, having a picnic.\\n\\nD. Women are bent over a field, planting seeds.   \n",
       "\n",
       "                                                                                                                                                                                                                                                        multiple_choice_question_easy  \\\n",
       "0  Question: Which of the following captions best describes the painting?\\n\\nA. Women are fishing in a river with nets.\\n\\nB. Women are bent over a river's edge, doing laundry.\\n\\nC. Women are having a picnic by the riverbank.\\n\\nD. Women are painting a landscape by the river.   \n",
       "\n",
       "  multiple_choice_prediction_easy multiple_choice_prediction_medium  \\\n",
       "0                               B                                 A   \n",
       "\n",
       "  multiple_choice_prediction_hard  ... multiple_choice_prediction_hard_Phi  \\\n",
       "0                               C  ...                                   B   \n",
       "\n",
       "  multiple_choice_prediction_easy_crop_phi  \\\n",
       "0                                        B   \n",
       "\n",
       "  multiple_choice_prediction_medium_crop_phi  \\\n",
       "0                                          B   \n",
       "\n",
       "  multiple_choice_prediction_hard_crop_phi  \\\n",
       "0                                        B   \n",
       "\n",
       "  multiple_choice_prediction_easy_saturation_phi  \\\n",
       "0                                              B   \n",
       "\n",
       "  multiple_choice_prediction_medium_saturation_phi  \\\n",
       "0                                                C   \n",
       "\n",
       "  multiple_choice_prediction_hard_saturation_phi  \\\n",
       "0                                              B   \n",
       "\n",
       "  multiple_choice_prediction_easy_noise_phi  \\\n",
       "0                                         B   \n",
       "\n",
       "  multiple_choice_prediction_medium_noise_phi  \\\n",
       "0                                           C   \n",
       "\n",
       "  multiple_choice_prediction_hard_noise_phi  \n",
       "0                                         B  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotation with multiple choice question result data file\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Directory: \n",
    "upking_annotation_file_path = '/shared/data/painting/paintings_with_MCQ_3diff_result_augmentation_phi.json'\n",
    "\n",
    "\n",
    "# Method 1: Using pandas.read_json directly\n",
    "df = pd.read_json(upking_annotation_file_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19844efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22eb2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "# BLEU Evaluation (Average across multiple references)\n",
    "def evaluate_bleu(df):\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption']  # Predicted caption\n",
    "\n",
    "        # Tokenize the candidate and reference captions\n",
    "        tokenized_references = [ref.strip('\"').split() for ref in references]  # List of tokenized references\n",
    "        tokenized_candidate = candidate.strip('\"').split()  # Tokenized candidate\n",
    "\n",
    "        # Compute BLEU for all references\n",
    "        row_bleu_scores = [\n",
    "            sentence_bleu([ref], tokenized_candidate) for ref in tokenized_references\n",
    "        ]\n",
    "        \n",
    "        # Average across references\n",
    "        bleu_scores.append(sum(row_bleu_scores) / len(row_bleu_scores))\n",
    "    \n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
    "    return bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ecf440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.571883312829026e-232,\n",
       " 8.962731118674859e-232,\n",
       " 9.269981669466712e-232,\n",
       " 5.746727420065187e-232,\n",
       " 0.0,\n",
       " 1.1337861261109773e-231,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6.085166479973199e-232,\n",
       " 1.0662520804273401e-231,\n",
       " 1.268852357850863e-231,\n",
       " 5.035580399326033e-155,\n",
       " 0.0,\n",
       " 2.6616657200018397e-78,\n",
       " 6.695492068419091e-232,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 5.748666558742058e-232,\n",
       " 0.0,\n",
       " 5.294085324363193e-232,\n",
       " 1.0709749285266912e-231,\n",
       " 4.491405484477833e-232,\n",
       " 1.0244914152188952e-231,\n",
       " 9.065607048138757e-232,\n",
       " 2.738929881729733e-232,\n",
       " 6.085166479973199e-232,\n",
       " 1.8423401430089077e-155,\n",
       " 4.685504009359912e-155,\n",
       " 1.3416480207402436e-231,\n",
       " 8.672642734733089e-232,\n",
       " 9.134374972545899e-232,\n",
       " 1.1896457329133973e-231,\n",
       " 1.0003688322288243e-231,\n",
       " 5.347469696085671e-155,\n",
       " 1.1896457329133973e-231,\n",
       " 0.0,\n",
       " 1.0709749285266912e-231,\n",
       " 5.554837769749797e-155,\n",
       " 0.0,\n",
       " 1.0003688322288243e-231,\n",
       " 2.5573972968570177e-155,\n",
       " 4.801280454758726e-232,\n",
       " 5.586496301804011e-232,\n",
       " 1.154647032204335e-231,\n",
       " 4.447844384793538e-155,\n",
       " 9.594503055152632e-232,\n",
       " 1.1200407237786664e-231,\n",
       " 4.930629612556808e-155,\n",
       " 1.1008876702055895e-231,\n",
       " 1.1640469867513693e-231,\n",
       " 1.1200407237786664e-231,\n",
       " 8.726094729337945e-232,\n",
       " 7.58961907326157e-232,\n",
       " 3.952279160832715e-155,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.101024727239516e-155,\n",
       " 6.113456099502214e-155,\n",
       " 4.368048869756373e-155,\n",
       " 4.654437852936961e-232,\n",
       " 2.0140843428031594e-78,\n",
       " 1.268852357850863e-231,\n",
       " 4.3593518747857304e-155,\n",
       " 9.918892480173173e-232,\n",
       " 4.811208997101563e-155,\n",
       " 4.717068855239749e-155,\n",
       " 5.308748212294969e-155,\n",
       " 1.12925133750994e-231,\n",
       " 1.4809931627947726e-78,\n",
       " 2.77975147435408e-155,\n",
       " 2.514766346395224e-155,\n",
       " 4.3382562373312645e-155,\n",
       " 1.0356031510602797e-231,\n",
       " 0.10248656832135973,\n",
       " 2.5241848589197885e-78,\n",
       " 4.431329581760117e-155,\n",
       " 2.166832421212117e-78,\n",
       " 4.15475484660171e-155,\n",
       " 3.0333872372477996e-155,\n",
       " 8.47838036897581e-232,\n",
       " 3.0857088441767165e-232,\n",
       " 0.0,\n",
       " 2.833381309242575e-233,\n",
       " 1.692841243110689e-232,\n",
       " 8.691336740174417e-233,\n",
       " 1.355408971519012e-231,\n",
       " 3.429482526394057e-155,\n",
       " 1.1008876702055895e-231,\n",
       " 7.332960415391412e-232,\n",
       " 1.929421779987532e-232,\n",
       " 3.4625676872110776e-232,\n",
       " 4.481994719908145e-232,\n",
       " 9.424890216415306e-232,\n",
       " 1.0428282296630707e-231,\n",
       " 6.744160953836975e-232,\n",
       " 1.1896457329133973e-231,\n",
       " 2.1863213053063146e-232,\n",
       " 3.103614158540553e-232,\n",
       " 3.6846889193984664e-232,\n",
       " 5.294085324363193e-232]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bleu(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1191486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/de/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# METEOR Evaluation (Average across multiple references)\n",
    "def evaluate_meteor(df):\n",
    "    meteor_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption'].strip('\"')  # Predicted caption (raw string)\n",
    "\n",
    "        # Compute METEOR for all references\n",
    "        row_meteor_scores = [\n",
    "            meteor_score([[ref]], [candidate]) for ref in references\n",
    "        ]\n",
    "        \n",
    "        # Average across references\n",
    "        meteor_scores.append(sum(row_meteor_scores) / len(row_meteor_scores))\n",
    "    \n",
    "    avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "    print(f\"Average METEOR: {avg_meteor:.4f}\")\n",
    "    return meteor_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef6f6412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average METEOR: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_meteor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9438e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9946f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE Evaluation (Average across multiple references)\n",
    "def evaluate_rouge(df):\n",
    "    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        references = row['reference_caption']  # List of reference captions\n",
    "        candidate = row['predicted_caption']  # Predicted caption\n",
    "        \n",
    "        # Compute ROUGE scores for all references\n",
    "        row_rouge1_scores, row_rouge2_scores, row_rougeL_scores = [], [], []\n",
    "        for ref in references:\n",
    "            scores = scorer.score(ref, candidate.strip('\"'))\n",
    "            row_rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            row_rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            row_rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        \n",
    "        # Average across references\n",
    "        rouge1_scores.append(sum(row_rouge1_scores) / len(row_rouge1_scores))\n",
    "        rouge2_scores.append(sum(row_rouge2_scores) / len(row_rouge2_scores))\n",
    "        rougeL_scores.append(sum(row_rougeL_scores) / len(row_rougeL_scores))\n",
    "    \n",
    "    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
    "    avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
    "    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
    "    \n",
    "    print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "    print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "    print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")\n",
    "    return rouge1_scores, rouge2_scores, rougeL_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e707a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: 0.4267\n",
      "Average ROUGE-2: 0.1000\n",
      "Average ROUGE-L: 0.3457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.3157894736842105, 0.5714285714285714, 0.3928571428571428],\n",
       " [0.0, 0.3, 0.0],\n",
       " [0.2631578947368421, 0.5238095238095238, 0.25])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rouge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIDEr and SPICE (unchanged, since they handle multiple references internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9a9ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cider(df):\n",
    "    ref_dict = {str(idx): row['reference_caption'] for idx, row in df.iterrows()}\n",
    "    cand_dict = {str(idx): [row['predicted_caption']] for idx, row in df.iterrows()}\n",
    "    \n",
    "    cider_scorer = Cider()\n",
    "    score, _ = cider_scorer.compute_score(ref_dict, cand_dict)\n",
    "    print(f\"Average CIDEr: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab777ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CIDEr: 0.7787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7786648935891062"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_cider(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618198b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3466d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_spice(df):\n",
    "    ref_dict = {str(idx): row['reference_caption'] for idx, row in df.iterrows()}\n",
    "    cand_dict = {str(idx): [row['predicted_caption']] for idx, row in df.iterrows()}\n",
    "    \n",
    "    spice_scorer = Spice()\n",
    "    score, _ = spice_scorer.compute_score(ref_dict, cand_dict)\n",
    "    print(f\"Average SPICE: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db09381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/opt/conda/lib/python3.10/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.890 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.995 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.85 s\n",
      "Average SPICE: 0.2341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23411371237458198"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_spice(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1614075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
